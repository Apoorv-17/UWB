{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UWB_Gesture_Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UWB Gesture Detection"
      ],
      "metadata": {
        "id": "oeyuLHWhIyee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning the GitHub repo to get the datset"
      ],
      "metadata": {
        "id": "89CgZ-kNHOxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Apoorv-17/UWB.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnr7xbWZJD0p",
        "outputId": "bca06646-c693-4856-a3be-746b2ed4fd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UWB'...\n",
            "remote: Enumerating objects: 13440, done.\u001b[K\n",
            "remote: Counting objects: 100% (13440/13440), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12383/12383), done.\u001b[K\n",
            "remote: Total 13440 (delta 1054), reused 13437 (delta 1054), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (13440/13440), 32.42 MiB | 15.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1054/1054), done.\n",
            "Checking out files: 100% (13505/13505), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries\n"
      ],
      "metadata": {
        "id": "xW9g_e9tJJmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img,ImageDataGenerator, array_to_img\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten,Dense,Conv2D,Dropout,GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import imutils    "
      ],
      "metadata": {
        "id": "kCPuqzlCJN1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "EtRFOlHmM8LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Navigation folders\n"
      ],
      "metadata": {
        "id": "BO_Us7MSNSoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = '/content/UWB/Dataset/modifiedData/'\n",
        "dataList = os.listdir('/content/UWB/Dataset/modifiedData/')"
      ],
      "metadata": {
        "id": "VjbXB3PPNQW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize labels array\n"
      ],
      "metadata": {
        "id": "3OO2DiOJNxEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.zeros(len(dataList))\n",
        "X = np.empty((1,990), float)"
      ],
      "metadata": {
        "id": "Z6I5cd8-N1o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(X, labels):\n",
        "    try:\n",
        "        i = 0\n",
        "        # Prepare dataset\n",
        "        for filename in dataList:\n",
        "            if 'rect' in filename:\n",
        "                y[i] = 1\n",
        "            data = np.genfromtxt(filePath + filename, delimiter=',').flatten()\n",
        "            data = np.reshape(data, (-1,990))\n",
        "            X = np.concatenate((X, data), axis=0)\n",
        "\n",
        "            i += 1\n",
        "    except:\n",
        "        print(filename)\n",
        "\n",
        "    # Clear first row\n",
        "    X = np.delete(X, 0, axis=0)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "CBWOXLOFN3sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = prepare_dataset(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
      ],
      "metadata": {
        "id": "f61sKBRzN6R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier"
      ],
      "metadata": {
        "id": "h49nmwGchYjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomForestCalc(X_train, X_test, y_train, y_test):\n",
        "    print('-------------------------------------------')\n",
        "    print('------------- Random Forest ---------------')\n",
        "\n",
        "    # Random Forest Algorithm\n",
        "    clf = RandomForestClassifier(n_estimators=80)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    rf_acc = metrics.accuracy_score(y_test, y_pred)\n",
        "    # acc_list.append(rf_acc)\n",
        "    # if rf_acc > max_acc:\n",
        "    #     max_acc = rf_acc\n",
        "    #     max_est = n_est\n",
        "    rf_prec = metrics.precision_score(y_test, y_pred)\n",
        "    rf_rec = metrics.recall_score(y_test, y_pred)\n",
        "    print('Accuracy: ', rf_acc)\n",
        "    print('Precision: ', rf_prec)\n",
        "    print('Recall: ', rf_rec)\n",
        "    Fscore = 2 * rf_rec * rf_prec / (rf_rec + rf_prec)\n",
        "    print('F-score: ', Fscore)    \n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt='0.0f')\n",
        "    plt.show()\n",
        "    print('-------------------------------------------')"
      ],
      "metadata": {
        "id": "RafbeZY7PMZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Classifier"
      ],
      "metadata": {
        "id": "YHccTUb1heFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def XGBoostCalc(X_train, X_test, y_train, y_test):\n",
        "    print('-------------------------------------------')\n",
        "    print('--------------- XGBoost -------------------')\n",
        "\n",
        "    # XGBoost Algorithm\n",
        "    D_train = xgb.DMatrix(X_train, label=y_train)\n",
        "    D_test = xgb.DMatrix(X_test, label=y_test)\n",
        "    param = {\n",
        "        'eta': 0.2,\n",
        "        'max_depth': 3,\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 2}\n",
        "    steps = 100\n",
        "    model = xgb.train(param, D_train, steps)\n",
        "    preds = model.predict(D_test)\n",
        "    best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "    xgb_acc = accuracy_score(y_test, best_preds)\n",
        "    xgb_prec = precision_score(y_test, best_preds, average='macro')\n",
        "    xgb_rec = recall_score(y_test, best_preds, average='macro')\n",
        "    print('Accuracy = {}'.format(xgb_acc))\n",
        "    print('Precision = {}'.format(xgb_prec))\n",
        "    print('Recall = {}'.format(xgb_rec))\n",
        "    Fscore = 2 * xgb_rec * xgb_prec / (xgb_rec + xgb_prec)\n",
        "    print('F-score: ', Fscore)\n",
        "    sns.heatmap(confusion_matrix(y_test, best_preds), annot = True, fmt='0.0f')\n",
        "    plt.show()\n",
        "    print('-------------------------------------------')"
      ],
      "metadata": {
        "id": "vyfB6XJXhhHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomForestCalc(X_train, X_test, y_train, y_test)\n",
        "XGBoostCalc(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "Z_-dNiQQhnmr",
        "outputId": "41dfb778-002c-4781-fd0a-024ef274352f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n",
            "------------- Random Forest ---------------\n",
            "Accuracy:  0.8757396449704142\n",
            "Precision:  0.8412698412698413\n",
            "Recall:  0.828125\n",
            "F-score:  0.8346456692913385\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "--------------- XGBoost -------------------\n",
            "Accuracy = 0.8165680473372781\n",
            "Precision = 0.8225340136054422\n",
            "Recall = 0.7822172619047619\n",
            "F-score:  0.8018691915249293\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Id5ytZRzhnjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QKWpRPUShnb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network\n",
        " "
      ],
      "metadata": {
        "id": "ZEpUGUv8P-6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.layers import InputLayer, Dense, ReLU, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "GW9opBZTQCKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to prepare the dataset\n",
        "def prepare_dataset(X, labels):\n",
        "    i = 0\n",
        "    # Prepare dataset\n",
        "    for filename in dataList:\n",
        "        if 'rect' in filename:\n",
        "            y[i] = 1\n",
        "        data = np.genfromtxt(filePath + filename, delimiter=',').flatten()\n",
        "        data = np.reshape(data, (-1,990))\n",
        "        X = np.concatenate((X, data), axis=0)\n",
        "        i += 1\n",
        "    # Clear first row\n",
        "    X = np.delete(X, 0, axis=0)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "F1kjSdqnQCmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = '/content/UWB/Dataset/modifiedData/'\n",
        "dataList = os.listdir('/content/UWB/Dataset/modifiedData/')"
      ],
      "metadata": {
        "id": "YJmM0fDiQL2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize labels array\n",
        "y = np.zeros(len(dataList))\n",
        "X = np.empty((1,990), float)"
      ],
      "metadata": {
        "id": "M_IF_q_aQctM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the method to adjust the dataset and split it into train/test parts\n",
        "X, y = prepare_dataset(X, y)"
      ],
      "metadata": {
        "id": "IgMOqgfcQekw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize number of estimations for fold, cross_validation score list and\n",
        "# confusion matrix init\n",
        "n_est = 5\n",
        "crs_val_fold = []\n",
        "iter = 0\n",
        "conf_arr = []\n",
        "history_rec = []"
      ],
      "metadata": {
        "id": "q0KA11SPQgFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the splitting based on number of estimations for StratifiedKFold\n",
        "for train_ind, test_ind in StratifiedKFold(n_est, shuffle=True).split(X, y):\n",
        "    X_train, X_test = X[train_ind], X[test_ind]\n",
        "    y_train, y_test = y[train_ind], y[test_ind]\n",
        "\n",
        "    # Setup and train the model\n",
        "    model = Sequential([\n",
        "        InputLayer((990,)),\n",
        "        Dense(64),\n",
        "        Dropout(0.5),\n",
        "        ReLU(),\n",
        "        Dense(32),\n",
        "        Dropout(0.5),\n",
        "        ReLU(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['acc'])\n",
        "\n",
        "    weight_name = 'weights' + str(iter) + '.h5'\n",
        "\n",
        "    # Train the model\n",
        "    # Two callbackes added for weight saving and stopping training\n",
        "    # if the accuraccy is not improveed over 30 iterations\n",
        "    save_best = ModelCheckpoint(filepath='nnData/' + weight_name,\n",
        "                                verbose=0, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(patience=30)\n",
        "    history = model.fit(X_train, y_train,\n",
        "              epochs=400,\n",
        "              validation_data=(X_test, y_test),\n",
        "              callbacks=[save_best, early_stopping])\n",
        "\n",
        "    # Append model results for further processing\n",
        "    history_rec.append(history)\n",
        "\n",
        "    # Evaluate the test set for fold\n",
        "    scores = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # Plot the confusion matrix and score for each fold\n",
        "    iter += 1\n",
        "    print(\"%s: %.2f%%\" % ('Accuracy: ', scores[1]*100))\n",
        "    crs_val_fold.append(scores[1] * 100)\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    conf_arr.append(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Icwea2RGiP",
        "outputId": "6a76cbf1-0ad9-475b-ece8-4138e677caf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 64)                63424     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 32)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "14/14 [==============================] - 1s 32ms/step - loss: 0.6891 - acc: 0.5804 - val_loss: 0.6836 - val_acc: 0.5929\n",
            "Epoch 2/400\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.6806 - acc: 0.5826 - val_loss: 0.6785 - val_acc: 0.5929\n",
            "Epoch 3/400\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.6794 - acc: 0.5960 - val_loss: 0.6741 - val_acc: 0.5929\n",
            "Epoch 4/400\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.6687 - acc: 0.6027 - val_loss: 0.6716 - val_acc: 0.5929\n",
            "Epoch 5/400\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.6691 - acc: 0.5982 - val_loss: 0.6692 - val_acc: 0.5929\n",
            "Epoch 6/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6646 - acc: 0.6004 - val_loss: 0.6671 - val_acc: 0.5929\n",
            "Epoch 7/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6685 - acc: 0.5938 - val_loss: 0.6645 - val_acc: 0.5929\n",
            "Epoch 8/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6642 - acc: 0.5960 - val_loss: 0.6619 - val_acc: 0.5929\n",
            "Epoch 9/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6592 - acc: 0.6004 - val_loss: 0.6583 - val_acc: 0.5929\n",
            "Epoch 10/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6515 - acc: 0.5938 - val_loss: 0.6534 - val_acc: 0.5929\n",
            "Epoch 11/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.6410 - acc: 0.6183 - val_loss: 0.6458 - val_acc: 0.5929\n",
            "Epoch 12/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6413 - acc: 0.6250 - val_loss: 0.6380 - val_acc: 0.5929\n",
            "Epoch 13/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6375 - acc: 0.6451 - val_loss: 0.6299 - val_acc: 0.5929\n",
            "Epoch 14/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6272 - acc: 0.6339 - val_loss: 0.6199 - val_acc: 0.6195\n",
            "Epoch 15/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6206 - acc: 0.6585 - val_loss: 0.6091 - val_acc: 0.6726\n",
            "Epoch 16/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6034 - acc: 0.6830 - val_loss: 0.6025 - val_acc: 0.6106\n",
            "Epoch 17/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6029 - acc: 0.6897 - val_loss: 0.5883 - val_acc: 0.7522\n",
            "Epoch 18/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5904 - acc: 0.6942 - val_loss: 0.5756 - val_acc: 0.7611\n",
            "Epoch 19/400\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5607 - acc: 0.7232 - val_loss: 0.5606 - val_acc: 0.7788\n",
            "Epoch 20/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5660 - acc: 0.7299 - val_loss: 0.5480 - val_acc: 0.7699\n",
            "Epoch 21/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5502 - acc: 0.7589 - val_loss: 0.5367 - val_acc: 0.7788\n",
            "Epoch 22/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5117 - acc: 0.7835 - val_loss: 0.5206 - val_acc: 0.7876\n",
            "Epoch 23/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.5148 - acc: 0.7879 - val_loss: 0.5059 - val_acc: 0.7876\n",
            "Epoch 24/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4984 - acc: 0.8058 - val_loss: 0.4930 - val_acc: 0.7876\n",
            "Epoch 25/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4869 - acc: 0.8170 - val_loss: 0.4805 - val_acc: 0.8053\n",
            "Epoch 26/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4908 - acc: 0.7946 - val_loss: 0.4640 - val_acc: 0.8053\n",
            "Epoch 27/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.4578 - acc: 0.8281 - val_loss: 0.4558 - val_acc: 0.8053\n",
            "Epoch 28/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.4488 - acc: 0.8326 - val_loss: 0.4327 - val_acc: 0.8142\n",
            "Epoch 29/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4203 - acc: 0.8728 - val_loss: 0.4238 - val_acc: 0.8407\n",
            "Epoch 30/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4142 - acc: 0.8549 - val_loss: 0.4032 - val_acc: 0.8230\n",
            "Epoch 31/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.4075 - acc: 0.8549 - val_loss: 0.3884 - val_acc: 0.8407\n",
            "Epoch 32/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.3788 - acc: 0.8705 - val_loss: 0.3888 - val_acc: 0.8496\n",
            "Epoch 33/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3625 - acc: 0.8571 - val_loss: 0.3590 - val_acc: 0.8496\n",
            "Epoch 34/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3539 - acc: 0.8817 - val_loss: 0.3459 - val_acc: 0.8584\n",
            "Epoch 35/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3455 - acc: 0.8728 - val_loss: 0.3345 - val_acc: 0.8673\n",
            "Epoch 36/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.3261 - acc: 0.8996 - val_loss: 0.3404 - val_acc: 0.8407\n",
            "Epoch 37/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3109 - acc: 0.8795 - val_loss: 0.3078 - val_acc: 0.9027\n",
            "Epoch 38/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.3141 - acc: 0.9085 - val_loss: 0.2970 - val_acc: 0.8850\n",
            "Epoch 39/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3076 - acc: 0.8996 - val_loss: 0.2860 - val_acc: 0.9115\n",
            "Epoch 40/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2977 - acc: 0.9107 - val_loss: 0.2841 - val_acc: 0.9027\n",
            "Epoch 41/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2866 - acc: 0.9152 - val_loss: 0.2722 - val_acc: 0.9292\n",
            "Epoch 42/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2692 - acc: 0.9219 - val_loss: 0.2578 - val_acc: 0.9292\n",
            "Epoch 43/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2787 - acc: 0.9062 - val_loss: 0.2836 - val_acc: 0.8673\n",
            "Epoch 44/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2589 - acc: 0.9263 - val_loss: 0.2564 - val_acc: 0.9204\n",
            "Epoch 45/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.9062 - val_loss: 0.2410 - val_acc: 0.9204\n",
            "Epoch 46/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2644 - acc: 0.9241 - val_loss: 0.2763 - val_acc: 0.8673\n",
            "Epoch 47/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2397 - acc: 0.9241 - val_loss: 0.2257 - val_acc: 0.9381\n",
            "Epoch 48/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2395 - acc: 0.9353 - val_loss: 0.2256 - val_acc: 0.9381\n",
            "Epoch 49/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2411 - acc: 0.9241 - val_loss: 0.2262 - val_acc: 0.9381\n",
            "Epoch 50/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2218 - acc: 0.9353 - val_loss: 0.2245 - val_acc: 0.9204\n",
            "Epoch 51/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2192 - acc: 0.9219 - val_loss: 0.2093 - val_acc: 0.9381\n",
            "Epoch 52/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2197 - acc: 0.9353 - val_loss: 0.2160 - val_acc: 0.9469\n",
            "Epoch 53/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2101 - acc: 0.9420 - val_loss: 0.2102 - val_acc: 0.9292\n",
            "Epoch 54/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2026 - acc: 0.9420 - val_loss: 0.2183 - val_acc: 0.9027\n",
            "Epoch 55/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.2001 - acc: 0.9375 - val_loss: 0.2038 - val_acc: 0.9469\n",
            "Epoch 56/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1952 - acc: 0.9509 - val_loss: 0.1934 - val_acc: 0.9469\n",
            "Epoch 57/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1908 - acc: 0.9464 - val_loss: 0.1940 - val_acc: 0.9469\n",
            "Epoch 58/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1770 - acc: 0.9353 - val_loss: 0.1933 - val_acc: 0.9381\n",
            "Epoch 59/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1928 - acc: 0.9509 - val_loss: 0.1895 - val_acc: 0.9469\n",
            "Epoch 60/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1869 - acc: 0.9442 - val_loss: 0.1951 - val_acc: 0.9292\n",
            "Epoch 61/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1730 - acc: 0.9487 - val_loss: 0.1835 - val_acc: 0.9469\n",
            "Epoch 62/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1598 - acc: 0.9509 - val_loss: 0.1921 - val_acc: 0.9292\n",
            "Epoch 63/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1540 - acc: 0.9665 - val_loss: 0.2087 - val_acc: 0.9115\n",
            "Epoch 64/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1839 - acc: 0.9487 - val_loss: 0.1853 - val_acc: 0.9381\n",
            "Epoch 65/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1731 - acc: 0.9688 - val_loss: 0.1777 - val_acc: 0.9469\n",
            "Epoch 66/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1592 - acc: 0.9554 - val_loss: 0.1984 - val_acc: 0.9204\n",
            "Epoch 67/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1521 - acc: 0.9621 - val_loss: 0.1818 - val_acc: 0.9292\n",
            "Epoch 68/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1430 - acc: 0.9665 - val_loss: 0.1777 - val_acc: 0.9381\n",
            "Epoch 69/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1218 - acc: 0.9710 - val_loss: 0.1796 - val_acc: 0.9292\n",
            "Epoch 70/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1417 - acc: 0.9621 - val_loss: 0.1860 - val_acc: 0.9204\n",
            "Epoch 71/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1484 - acc: 0.9665 - val_loss: 0.1863 - val_acc: 0.9204\n",
            "Epoch 72/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1365 - acc: 0.9732 - val_loss: 0.1680 - val_acc: 0.9469\n",
            "Epoch 73/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1349 - acc: 0.9688 - val_loss: 0.1644 - val_acc: 0.9469\n",
            "Epoch 74/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1186 - acc: 0.9799 - val_loss: 0.1839 - val_acc: 0.9204\n",
            "Epoch 75/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1458 - acc: 0.9688 - val_loss: 0.1661 - val_acc: 0.9381\n",
            "Epoch 76/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1368 - acc: 0.9710 - val_loss: 0.1680 - val_acc: 0.9469\n",
            "Epoch 77/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1158 - acc: 0.9688 - val_loss: 0.1698 - val_acc: 0.9292\n",
            "Epoch 78/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1255 - acc: 0.9688 - val_loss: 0.1640 - val_acc: 0.9469\n",
            "Epoch 79/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1286 - acc: 0.9688 - val_loss: 0.1662 - val_acc: 0.9469\n",
            "Epoch 80/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1146 - acc: 0.9821 - val_loss: 0.1795 - val_acc: 0.9204\n",
            "Epoch 81/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1302 - acc: 0.9665 - val_loss: 0.1623 - val_acc: 0.9381\n",
            "Epoch 82/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1218 - acc: 0.9732 - val_loss: 0.1663 - val_acc: 0.9292\n",
            "Epoch 83/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1337 - acc: 0.9643 - val_loss: 0.1841 - val_acc: 0.9204\n",
            "Epoch 84/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1182 - acc: 0.9643 - val_loss: 0.1586 - val_acc: 0.9381\n",
            "Epoch 85/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1148 - acc: 0.9710 - val_loss: 0.1544 - val_acc: 0.9469\n",
            "Epoch 86/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1294 - acc: 0.9754 - val_loss: 0.1991 - val_acc: 0.9115\n",
            "Epoch 87/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1232 - acc: 0.9688 - val_loss: 0.1644 - val_acc: 0.9204\n",
            "Epoch 88/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1147 - acc: 0.9688 - val_loss: 0.1657 - val_acc: 0.9204\n",
            "Epoch 89/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0956 - acc: 0.9754 - val_loss: 0.1540 - val_acc: 0.9381\n",
            "Epoch 90/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1188 - acc: 0.9777 - val_loss: 0.1871 - val_acc: 0.9115\n",
            "Epoch 91/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1258 - acc: 0.9710 - val_loss: 0.1700 - val_acc: 0.9204\n",
            "Epoch 92/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1107 - acc: 0.9754 - val_loss: 0.1708 - val_acc: 0.9204\n",
            "Epoch 93/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1140 - acc: 0.9754 - val_loss: 0.1523 - val_acc: 0.9469\n",
            "Epoch 94/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0924 - acc: 0.9710 - val_loss: 0.1850 - val_acc: 0.9115\n",
            "Epoch 95/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1137 - acc: 0.9710 - val_loss: 0.1490 - val_acc: 0.9469\n",
            "Epoch 96/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1164 - acc: 0.9777 - val_loss: 0.1545 - val_acc: 0.9381\n",
            "Epoch 97/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0955 - acc: 0.9777 - val_loss: 0.1609 - val_acc: 0.9292\n",
            "Epoch 98/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1108 - acc: 0.9777 - val_loss: 0.1502 - val_acc: 0.9469\n",
            "Epoch 99/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0813 - acc: 0.9799 - val_loss: 0.1591 - val_acc: 0.9381\n",
            "Epoch 100/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0921 - acc: 0.9777 - val_loss: 0.1553 - val_acc: 0.9381\n",
            "Epoch 101/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1084 - acc: 0.9777 - val_loss: 0.1470 - val_acc: 0.9558\n",
            "Epoch 102/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0991 - acc: 0.9777 - val_loss: 0.1464 - val_acc: 0.9469\n",
            "Epoch 103/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1003 - acc: 0.9777 - val_loss: 0.1636 - val_acc: 0.9292\n",
            "Epoch 104/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0769 - acc: 0.9866 - val_loss: 0.1505 - val_acc: 0.9381\n",
            "Epoch 105/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1034 - acc: 0.9732 - val_loss: 0.1503 - val_acc: 0.9558\n",
            "Epoch 106/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0877 - acc: 0.9777 - val_loss: 0.1580 - val_acc: 0.9292\n",
            "Epoch 107/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0896 - acc: 0.9821 - val_loss: 0.1653 - val_acc: 0.9204\n",
            "Epoch 108/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0896 - acc: 0.9732 - val_loss: 0.1470 - val_acc: 0.9469\n",
            "Epoch 109/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0895 - acc: 0.9777 - val_loss: 0.1560 - val_acc: 0.9381\n",
            "Epoch 110/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0892 - acc: 0.9844 - val_loss: 0.1642 - val_acc: 0.9204\n",
            "Epoch 111/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0928 - acc: 0.9754 - val_loss: 0.1456 - val_acc: 0.9558\n",
            "Epoch 112/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0807 - acc: 0.9866 - val_loss: 0.1618 - val_acc: 0.9204\n",
            "Epoch 113/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0913 - acc: 0.9754 - val_loss: 0.1479 - val_acc: 0.9381\n",
            "Epoch 114/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0829 - acc: 0.9799 - val_loss: 0.1563 - val_acc: 0.9381\n",
            "Epoch 115/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0874 - acc: 0.9799 - val_loss: 0.1523 - val_acc: 0.9381\n",
            "Epoch 116/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0867 - acc: 0.9732 - val_loss: 0.1547 - val_acc: 0.9381\n",
            "Epoch 117/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0796 - acc: 0.9732 - val_loss: 0.1456 - val_acc: 0.9469\n",
            "Epoch 118/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0784 - acc: 0.9866 - val_loss: 0.1475 - val_acc: 0.9381\n",
            "Epoch 119/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0923 - acc: 0.9821 - val_loss: 0.1422 - val_acc: 0.9469\n",
            "Epoch 120/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0844 - acc: 0.9799 - val_loss: 0.1529 - val_acc: 0.9204\n",
            "Epoch 121/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0943 - acc: 0.9777 - val_loss: 0.1598 - val_acc: 0.9292\n",
            "Epoch 122/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0794 - acc: 0.9844 - val_loss: 0.1472 - val_acc: 0.9381\n",
            "Epoch 123/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0788 - acc: 0.9844 - val_loss: 0.1591 - val_acc: 0.9292\n",
            "Epoch 124/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0839 - acc: 0.9866 - val_loss: 0.1559 - val_acc: 0.9381\n",
            "Epoch 125/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0650 - acc: 0.9844 - val_loss: 0.1516 - val_acc: 0.9381\n",
            "Epoch 126/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0755 - acc: 0.9821 - val_loss: 0.1424 - val_acc: 0.9558\n",
            "Epoch 127/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0749 - acc: 0.9821 - val_loss: 0.1390 - val_acc: 0.9558\n",
            "Epoch 128/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0715 - acc: 0.9821 - val_loss: 0.1552 - val_acc: 0.9292\n",
            "Epoch 129/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0912 - acc: 0.9844 - val_loss: 0.1492 - val_acc: 0.9381\n",
            "Epoch 130/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0706 - acc: 0.9844 - val_loss: 0.1468 - val_acc: 0.9381\n",
            "Epoch 131/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0720 - acc: 0.9844 - val_loss: 0.1625 - val_acc: 0.9204\n",
            "Epoch 132/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0721 - acc: 0.9844 - val_loss: 0.1389 - val_acc: 0.9558\n",
            "Epoch 133/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0706 - acc: 0.9844 - val_loss: 0.1554 - val_acc: 0.9204\n",
            "Epoch 134/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0656 - acc: 0.9911 - val_loss: 0.1447 - val_acc: 0.9558\n",
            "Epoch 135/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0758 - acc: 0.9821 - val_loss: 0.1665 - val_acc: 0.9292\n",
            "Epoch 136/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0655 - acc: 0.9844 - val_loss: 0.1634 - val_acc: 0.9292\n",
            "Epoch 137/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0679 - acc: 0.9844 - val_loss: 0.1460 - val_acc: 0.9469\n",
            "Epoch 138/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0704 - acc: 0.9888 - val_loss: 0.1470 - val_acc: 0.9381\n",
            "Epoch 139/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0577 - acc: 0.9866 - val_loss: 0.1387 - val_acc: 0.9646\n",
            "Epoch 140/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0642 - acc: 0.9844 - val_loss: 0.1647 - val_acc: 0.9204\n",
            "Epoch 141/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0585 - acc: 0.9888 - val_loss: 0.1565 - val_acc: 0.9292\n",
            "Epoch 142/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0550 - acc: 0.9888 - val_loss: 0.1504 - val_acc: 0.9381\n",
            "Epoch 143/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0530 - acc: 0.9844 - val_loss: 0.1610 - val_acc: 0.9292\n",
            "Epoch 144/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0597 - acc: 0.9866 - val_loss: 0.1728 - val_acc: 0.9292\n",
            "Epoch 145/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0730 - acc: 0.9754 - val_loss: 0.1559 - val_acc: 0.9292\n",
            "Epoch 146/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0737 - acc: 0.9844 - val_loss: 0.1422 - val_acc: 0.9646\n",
            "Epoch 147/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0552 - acc: 0.9821 - val_loss: 0.1979 - val_acc: 0.9115\n",
            "Epoch 148/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0676 - acc: 0.9866 - val_loss: 0.1378 - val_acc: 0.9558\n",
            "Epoch 149/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0620 - acc: 0.9866 - val_loss: 0.1429 - val_acc: 0.9381\n",
            "Epoch 150/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0617 - acc: 0.9844 - val_loss: 0.1985 - val_acc: 0.9115\n",
            "Epoch 151/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - acc: 0.9799 - val_loss: 0.1411 - val_acc: 0.9558\n",
            "Epoch 152/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0708 - acc: 0.9777 - val_loss: 0.1475 - val_acc: 0.9381\n",
            "Epoch 153/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0742 - acc: 0.9866 - val_loss: 0.1440 - val_acc: 0.9558\n",
            "Epoch 154/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0602 - acc: 0.9844 - val_loss: 0.1662 - val_acc: 0.9292\n",
            "Epoch 155/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0577 - acc: 0.9911 - val_loss: 0.1610 - val_acc: 0.9292\n",
            "Epoch 156/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0522 - acc: 0.9911 - val_loss: 0.1393 - val_acc: 0.9646\n",
            "Epoch 157/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0620 - acc: 0.9866 - val_loss: 0.2078 - val_acc: 0.9027\n",
            "Epoch 158/400\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0612 - acc: 0.9888 - val_loss: 0.1354 - val_acc: 0.9646\n",
            "Epoch 159/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0669 - acc: 0.9821 - val_loss: 0.1603 - val_acc: 0.9381\n",
            "Epoch 160/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0530 - acc: 0.9866 - val_loss: 0.1571 - val_acc: 0.9381\n",
            "Epoch 161/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0698 - acc: 0.9821 - val_loss: 0.1602 - val_acc: 0.9292\n",
            "Epoch 162/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0533 - acc: 0.9933 - val_loss: 0.1708 - val_acc: 0.9292\n",
            "Epoch 163/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0636 - acc: 0.9844 - val_loss: 0.1883 - val_acc: 0.9115\n",
            "Epoch 164/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0603 - acc: 0.9866 - val_loss: 0.1390 - val_acc: 0.9646\n",
            "Epoch 165/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0698 - acc: 0.9821 - val_loss: 0.1951 - val_acc: 0.9115\n",
            "Epoch 166/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0632 - acc: 0.9866 - val_loss: 0.1662 - val_acc: 0.9292\n",
            "Epoch 167/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0496 - acc: 0.9911 - val_loss: 0.1601 - val_acc: 0.9381\n",
            "Epoch 168/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0672 - acc: 0.9799 - val_loss: 0.1557 - val_acc: 0.9381\n",
            "Epoch 169/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0516 - acc: 0.9888 - val_loss: 0.1788 - val_acc: 0.9204\n",
            "Epoch 170/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0599 - acc: 0.9799 - val_loss: 0.1581 - val_acc: 0.9381\n",
            "Epoch 171/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0428 - acc: 0.9911 - val_loss: 0.1628 - val_acc: 0.9381\n",
            "Epoch 172/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0560 - acc: 0.9888 - val_loss: 0.1481 - val_acc: 0.9558\n",
            "Epoch 173/400\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0419 - acc: 0.9933 - val_loss: 0.1453 - val_acc: 0.9646\n",
            "Epoch 174/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0536 - acc: 0.9866 - val_loss: 0.1929 - val_acc: 0.9204\n",
            "Epoch 175/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0602 - acc: 0.9844 - val_loss: 0.1521 - val_acc: 0.9381\n",
            "Epoch 176/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0444 - acc: 0.9888 - val_loss: 0.1964 - val_acc: 0.9204\n",
            "Epoch 177/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0428 - acc: 0.9888 - val_loss: 0.1638 - val_acc: 0.9381\n",
            "Epoch 178/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0452 - acc: 0.9911 - val_loss: 0.1579 - val_acc: 0.9646\n",
            "Epoch 179/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0538 - acc: 0.9911 - val_loss: 0.1539 - val_acc: 0.9381\n",
            "Epoch 180/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0479 - acc: 0.9866 - val_loss: 0.1705 - val_acc: 0.9204\n",
            "Epoch 181/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0474 - acc: 0.9888 - val_loss: 0.2034 - val_acc: 0.9204\n",
            "Epoch 182/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0452 - acc: 0.9911 - val_loss: 0.1732 - val_acc: 0.9204\n",
            "Epoch 183/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0512 - acc: 0.9933 - val_loss: 0.1606 - val_acc: 0.9381\n",
            "Epoch 184/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0419 - acc: 0.9888 - val_loss: 0.1756 - val_acc: 0.9204\n",
            "Epoch 185/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0523 - acc: 0.9844 - val_loss: 0.1680 - val_acc: 0.9292\n",
            "Epoch 186/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0461 - acc: 0.9866 - val_loss: 0.1562 - val_acc: 0.9469\n",
            "Epoch 187/400\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0568 - acc: 0.9799 - val_loss: 0.1990 - val_acc: 0.9115\n",
            "Epoch 188/400\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0515 - acc: 0.9888 - val_loss: 0.1605 - val_acc: 0.9292\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1605 - acc: 0.9292\n",
            "Accuracy: : 92.92%\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 64)                63424     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 32)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "15/15 [==============================] - 1s 21ms/step - loss: 0.6898 - acc: 0.5434 - val_loss: 0.6842 - val_acc: 0.5982\n",
            "Epoch 2/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6832 - acc: 0.5902 - val_loss: 0.6789 - val_acc: 0.5982\n",
            "Epoch 3/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6777 - acc: 0.5947 - val_loss: 0.6744 - val_acc: 0.5982\n",
            "Epoch 4/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6783 - acc: 0.5969 - val_loss: 0.6722 - val_acc: 0.5982\n",
            "Epoch 5/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6782 - acc: 0.5924 - val_loss: 0.6706 - val_acc: 0.5982\n",
            "Epoch 6/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6758 - acc: 0.5924 - val_loss: 0.6684 - val_acc: 0.5982\n",
            "Epoch 7/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6685 - acc: 0.5969 - val_loss: 0.6683 - val_acc: 0.5982\n",
            "Epoch 8/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6723 - acc: 0.5947 - val_loss: 0.6666 - val_acc: 0.5982\n",
            "Epoch 9/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6647 - acc: 0.6036 - val_loss: 0.6643 - val_acc: 0.5982\n",
            "Epoch 10/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6631 - acc: 0.5969 - val_loss: 0.6609 - val_acc: 0.5982\n",
            "Epoch 11/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6618 - acc: 0.5991 - val_loss: 0.6555 - val_acc: 0.5982\n",
            "Epoch 12/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6597 - acc: 0.6058 - val_loss: 0.6506 - val_acc: 0.5982\n",
            "Epoch 13/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6566 - acc: 0.6102 - val_loss: 0.6459 - val_acc: 0.5982\n",
            "Epoch 14/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6395 - acc: 0.6236 - val_loss: 0.6382 - val_acc: 0.5982\n",
            "Epoch 15/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6357 - acc: 0.6236 - val_loss: 0.6315 - val_acc: 0.5982\n",
            "Epoch 16/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6337 - acc: 0.6615 - val_loss: 0.6224 - val_acc: 0.6429\n",
            "Epoch 17/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6252 - acc: 0.6682 - val_loss: 0.6146 - val_acc: 0.6964\n",
            "Epoch 18/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6095 - acc: 0.6771 - val_loss: 0.6046 - val_acc: 0.7054\n",
            "Epoch 19/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6056 - acc: 0.7082 - val_loss: 0.5962 - val_acc: 0.7321\n",
            "Epoch 20/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5900 - acc: 0.7105 - val_loss: 0.5848 - val_acc: 0.7411\n",
            "Epoch 21/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5842 - acc: 0.6726 - val_loss: 0.5757 - val_acc: 0.7589\n",
            "Epoch 22/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5831 - acc: 0.7372 - val_loss: 0.5777 - val_acc: 0.7679\n",
            "Epoch 23/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5888 - acc: 0.6971 - val_loss: 0.5782 - val_acc: 0.7411\n",
            "Epoch 24/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5728 - acc: 0.7550 - val_loss: 0.5674 - val_acc: 0.7679\n",
            "Epoch 25/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5542 - acc: 0.7639 - val_loss: 0.5463 - val_acc: 0.7679\n",
            "Epoch 26/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5478 - acc: 0.7639 - val_loss: 0.5377 - val_acc: 0.7679\n",
            "Epoch 27/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5348 - acc: 0.8085 - val_loss: 0.5253 - val_acc: 0.7857\n",
            "Epoch 28/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5233 - acc: 0.7817 - val_loss: 0.5152 - val_acc: 0.7946\n",
            "Epoch 29/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5180 - acc: 0.7973 - val_loss: 0.5152 - val_acc: 0.8036\n",
            "Epoch 30/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5039 - acc: 0.8062 - val_loss: 0.5026 - val_acc: 0.8036\n",
            "Epoch 31/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5043 - acc: 0.7817 - val_loss: 0.4918 - val_acc: 0.8036\n",
            "Epoch 32/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5021 - acc: 0.7929 - val_loss: 0.4786 - val_acc: 0.8036\n",
            "Epoch 33/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4831 - acc: 0.8040 - val_loss: 0.4705 - val_acc: 0.8125\n",
            "Epoch 34/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4732 - acc: 0.8151 - val_loss: 0.4586 - val_acc: 0.8036\n",
            "Epoch 35/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4668 - acc: 0.8196 - val_loss: 0.4482 - val_acc: 0.8304\n",
            "Epoch 36/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4199 - acc: 0.8419 - val_loss: 0.4380 - val_acc: 0.8304\n",
            "Epoch 37/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4182 - acc: 0.8486 - val_loss: 0.4281 - val_acc: 0.8304\n",
            "Epoch 38/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4074 - acc: 0.8374 - val_loss: 0.4183 - val_acc: 0.8304\n",
            "Epoch 39/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4288 - acc: 0.8486 - val_loss: 0.4261 - val_acc: 0.8482\n",
            "Epoch 40/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4129 - acc: 0.8419 - val_loss: 0.4040 - val_acc: 0.8393\n",
            "Epoch 41/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3937 - acc: 0.8575 - val_loss: 0.3955 - val_acc: 0.8304\n",
            "Epoch 42/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3899 - acc: 0.8530 - val_loss: 0.3838 - val_acc: 0.8393\n",
            "Epoch 43/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3897 - acc: 0.8530 - val_loss: 0.3835 - val_acc: 0.8393\n",
            "Epoch 44/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3615 - acc: 0.8664 - val_loss: 0.3675 - val_acc: 0.8571\n",
            "Epoch 45/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3565 - acc: 0.8797 - val_loss: 0.3922 - val_acc: 0.8214\n",
            "Epoch 46/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4383 - acc: 0.7996 - val_loss: 0.4187 - val_acc: 0.8214\n",
            "Epoch 47/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3947 - acc: 0.8486 - val_loss: 0.3753 - val_acc: 0.8661\n",
            "Epoch 48/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3609 - acc: 0.8864 - val_loss: 0.3644 - val_acc: 0.8750\n",
            "Epoch 49/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3494 - acc: 0.8797 - val_loss: 0.3424 - val_acc: 0.8750\n",
            "Epoch 50/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3294 - acc: 0.8998 - val_loss: 0.3461 - val_acc: 0.8571\n",
            "Epoch 51/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3395 - acc: 0.8753 - val_loss: 0.3307 - val_acc: 0.8750\n",
            "Epoch 52/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3364 - acc: 0.8686 - val_loss: 0.3267 - val_acc: 0.8661\n",
            "Epoch 53/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3078 - acc: 0.8998 - val_loss: 0.3308 - val_acc: 0.8482\n",
            "Epoch 54/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3388 - acc: 0.8686 - val_loss: 0.3264 - val_acc: 0.8750\n",
            "Epoch 55/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3102 - acc: 0.9042 - val_loss: 0.3104 - val_acc: 0.8839\n",
            "Epoch 56/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2798 - acc: 0.9020 - val_loss: 0.3074 - val_acc: 0.8750\n",
            "Epoch 57/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2748 - acc: 0.9198 - val_loss: 0.3047 - val_acc: 0.8661\n",
            "Epoch 58/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2785 - acc: 0.9109 - val_loss: 0.3074 - val_acc: 0.8661\n",
            "Epoch 59/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2606 - acc: 0.9176 - val_loss: 0.2926 - val_acc: 0.8929\n",
            "Epoch 60/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2546 - acc: 0.8931 - val_loss: 0.2900 - val_acc: 0.8929\n",
            "Epoch 61/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2732 - acc: 0.9020 - val_loss: 0.2968 - val_acc: 0.8750\n",
            "Epoch 62/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2734 - acc: 0.9042 - val_loss: 0.2833 - val_acc: 0.9107\n",
            "Epoch 63/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2510 - acc: 0.9376 - val_loss: 0.2823 - val_acc: 0.8839\n",
            "Epoch 64/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2725 - acc: 0.9042 - val_loss: 0.2800 - val_acc: 0.8839\n",
            "Epoch 65/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2343 - acc: 0.9287 - val_loss: 0.2720 - val_acc: 0.9018\n",
            "Epoch 66/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2286 - acc: 0.9332 - val_loss: 0.2726 - val_acc: 0.8929\n",
            "Epoch 67/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2298 - acc: 0.9332 - val_loss: 0.2767 - val_acc: 0.8929\n",
            "Epoch 68/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2267 - acc: 0.9287 - val_loss: 0.2715 - val_acc: 0.9107\n",
            "Epoch 69/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2746 - acc: 0.9020 - val_loss: 0.2955 - val_acc: 0.8929\n",
            "Epoch 70/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2306 - acc: 0.9131 - val_loss: 0.2642 - val_acc: 0.9107\n",
            "Epoch 71/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2103 - acc: 0.9310 - val_loss: 0.2671 - val_acc: 0.8929\n",
            "Epoch 72/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2382 - acc: 0.9042 - val_loss: 0.2645 - val_acc: 0.9018\n",
            "Epoch 73/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2093 - acc: 0.9421 - val_loss: 0.2568 - val_acc: 0.8929\n",
            "Epoch 74/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1984 - acc: 0.9287 - val_loss: 0.2562 - val_acc: 0.9018\n",
            "Epoch 75/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2446 - acc: 0.9354 - val_loss: 0.2824 - val_acc: 0.9018\n",
            "Epoch 76/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2200 - acc: 0.9265 - val_loss: 0.2555 - val_acc: 0.8929\n",
            "Epoch 77/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2245 - acc: 0.9243 - val_loss: 0.2749 - val_acc: 0.9018\n",
            "Epoch 78/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2098 - acc: 0.9243 - val_loss: 0.2565 - val_acc: 0.9107\n",
            "Epoch 79/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3312 - acc: 0.8664 - val_loss: 0.3114 - val_acc: 0.8839\n",
            "Epoch 80/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2543 - acc: 0.8931 - val_loss: 0.2674 - val_acc: 0.8929\n",
            "Epoch 81/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2000 - acc: 0.9399 - val_loss: 0.2631 - val_acc: 0.9018\n",
            "Epoch 82/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2754 - acc: 0.8842 - val_loss: 0.3102 - val_acc: 0.8929\n",
            "Epoch 83/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2231 - acc: 0.9220 - val_loss: 0.2534 - val_acc: 0.9107\n",
            "Epoch 84/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2021 - acc: 0.9376 - val_loss: 0.2561 - val_acc: 0.9018\n",
            "Epoch 85/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2162 - acc: 0.9198 - val_loss: 0.2494 - val_acc: 0.9018\n",
            "Epoch 86/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2040 - acc: 0.9399 - val_loss: 0.2574 - val_acc: 0.9107\n",
            "Epoch 87/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2142 - acc: 0.9421 - val_loss: 0.2552 - val_acc: 0.9107\n",
            "Epoch 88/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2065 - acc: 0.9376 - val_loss: 0.2529 - val_acc: 0.9018\n",
            "Epoch 89/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2026 - acc: 0.9354 - val_loss: 0.2528 - val_acc: 0.9107\n",
            "Epoch 90/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2022 - acc: 0.9376 - val_loss: 0.2533 - val_acc: 0.9196\n",
            "Epoch 91/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1791 - acc: 0.9599 - val_loss: 0.2500 - val_acc: 0.9107\n",
            "Epoch 92/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2068 - acc: 0.9131 - val_loss: 0.2459 - val_acc: 0.9107\n",
            "Epoch 93/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1750 - acc: 0.9465 - val_loss: 0.2579 - val_acc: 0.9196\n",
            "Epoch 94/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1589 - acc: 0.9354 - val_loss: 0.2451 - val_acc: 0.9018\n",
            "Epoch 95/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1789 - acc: 0.9443 - val_loss: 0.2546 - val_acc: 0.9196\n",
            "Epoch 96/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1541 - acc: 0.9421 - val_loss: 0.2594 - val_acc: 0.9196\n",
            "Epoch 97/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1624 - acc: 0.9465 - val_loss: 0.2430 - val_acc: 0.9107\n",
            "Epoch 98/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1599 - acc: 0.9488 - val_loss: 0.2418 - val_acc: 0.9107\n",
            "Epoch 99/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1502 - acc: 0.9465 - val_loss: 0.2426 - val_acc: 0.9107\n",
            "Epoch 100/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1679 - acc: 0.9465 - val_loss: 0.2396 - val_acc: 0.9107\n",
            "Epoch 101/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1572 - acc: 0.9465 - val_loss: 0.2668 - val_acc: 0.9018\n",
            "Epoch 102/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2426 - acc: 0.9020 - val_loss: 0.2927 - val_acc: 0.9107\n",
            "Epoch 103/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2194 - acc: 0.9087 - val_loss: 0.2534 - val_acc: 0.9196\n",
            "Epoch 104/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1705 - acc: 0.9443 - val_loss: 0.2412 - val_acc: 0.9107\n",
            "Epoch 105/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1606 - acc: 0.9532 - val_loss: 0.2447 - val_acc: 0.9107\n",
            "Epoch 106/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1528 - acc: 0.9510 - val_loss: 0.2386 - val_acc: 0.9107\n",
            "Epoch 107/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1431 - acc: 0.9666 - val_loss: 0.2440 - val_acc: 0.9107\n",
            "Epoch 108/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1594 - acc: 0.9510 - val_loss: 0.2402 - val_acc: 0.9018\n",
            "Epoch 109/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1883 - acc: 0.9354 - val_loss: 0.2440 - val_acc: 0.9196\n",
            "Epoch 110/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1689 - acc: 0.9488 - val_loss: 0.2410 - val_acc: 0.9107\n",
            "Epoch 111/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2170 - acc: 0.9265 - val_loss: 0.2429 - val_acc: 0.9107\n",
            "Epoch 112/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1814 - acc: 0.9465 - val_loss: 0.2411 - val_acc: 0.9196\n",
            "Epoch 113/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1912 - acc: 0.9243 - val_loss: 0.2376 - val_acc: 0.9107\n",
            "Epoch 114/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1732 - acc: 0.9488 - val_loss: 0.2369 - val_acc: 0.9107\n",
            "Epoch 115/400\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1634 - acc: 0.9555 - val_loss: 0.2420 - val_acc: 0.9107\n",
            "Epoch 116/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1779 - acc: 0.9399 - val_loss: 0.2388 - val_acc: 0.9107\n",
            "Epoch 117/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1553 - acc: 0.9532 - val_loss: 0.2386 - val_acc: 0.9107\n",
            "Epoch 118/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1175 - acc: 0.9644 - val_loss: 0.2371 - val_acc: 0.9107\n",
            "Epoch 119/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1305 - acc: 0.9688 - val_loss: 0.2539 - val_acc: 0.9196\n",
            "Epoch 120/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1400 - acc: 0.9644 - val_loss: 0.2394 - val_acc: 0.9107\n",
            "Epoch 121/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1529 - acc: 0.9399 - val_loss: 0.2371 - val_acc: 0.9107\n",
            "Epoch 122/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1419 - acc: 0.9577 - val_loss: 0.2373 - val_acc: 0.9107\n",
            "Epoch 123/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1292 - acc: 0.9710 - val_loss: 0.2426 - val_acc: 0.9196\n",
            "Epoch 124/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1631 - acc: 0.9421 - val_loss: 0.2324 - val_acc: 0.9107\n",
            "Epoch 125/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1250 - acc: 0.9688 - val_loss: 0.2489 - val_acc: 0.9286\n",
            "Epoch 126/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1158 - acc: 0.9710 - val_loss: 0.2358 - val_acc: 0.9107\n",
            "Epoch 127/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1468 - acc: 0.9532 - val_loss: 0.2907 - val_acc: 0.9107\n",
            "Epoch 128/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1397 - acc: 0.9488 - val_loss: 0.2332 - val_acc: 0.9107\n",
            "Epoch 129/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1517 - acc: 0.9443 - val_loss: 0.2347 - val_acc: 0.9107\n",
            "Epoch 130/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1261 - acc: 0.9555 - val_loss: 0.2292 - val_acc: 0.9107\n",
            "Epoch 131/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1577 - acc: 0.9465 - val_loss: 0.2279 - val_acc: 0.9107\n",
            "Epoch 132/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1325 - acc: 0.9666 - val_loss: 0.2338 - val_acc: 0.9107\n",
            "Epoch 133/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1424 - acc: 0.9488 - val_loss: 0.2488 - val_acc: 0.9286\n",
            "Epoch 134/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1215 - acc: 0.9666 - val_loss: 0.2328 - val_acc: 0.9196\n",
            "Epoch 135/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2232 - acc: 0.9287 - val_loss: 0.2582 - val_acc: 0.9286\n",
            "Epoch 136/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2503 - acc: 0.9065 - val_loss: 0.2492 - val_acc: 0.9286\n",
            "Epoch 137/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1959 - acc: 0.9644 - val_loss: 0.2384 - val_acc: 0.9196\n",
            "Epoch 138/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1760 - acc: 0.9443 - val_loss: 0.2310 - val_acc: 0.9107\n",
            "Epoch 139/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1681 - acc: 0.9555 - val_loss: 0.2437 - val_acc: 0.9286\n",
            "Epoch 140/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1560 - acc: 0.9666 - val_loss: 0.2319 - val_acc: 0.9107\n",
            "Epoch 141/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1588 - acc: 0.9465 - val_loss: 0.2353 - val_acc: 0.9286\n",
            "Epoch 142/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1535 - acc: 0.9577 - val_loss: 0.2308 - val_acc: 0.9107\n",
            "Epoch 143/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1495 - acc: 0.9577 - val_loss: 0.2331 - val_acc: 0.9196\n",
            "Epoch 144/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1794 - acc: 0.9399 - val_loss: 0.2370 - val_acc: 0.9286\n",
            "Epoch 145/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1808 - acc: 0.9421 - val_loss: 0.2328 - val_acc: 0.9196\n",
            "Epoch 146/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1564 - acc: 0.9465 - val_loss: 0.2396 - val_acc: 0.9286\n",
            "Epoch 147/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1665 - acc: 0.9399 - val_loss: 0.2331 - val_acc: 0.9286\n",
            "Epoch 148/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1462 - acc: 0.9599 - val_loss: 0.2364 - val_acc: 0.9286\n",
            "Epoch 149/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1502 - acc: 0.9599 - val_loss: 0.2314 - val_acc: 0.9107\n",
            "Epoch 150/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1568 - acc: 0.9488 - val_loss: 0.2321 - val_acc: 0.9107\n",
            "Epoch 151/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1498 - acc: 0.9577 - val_loss: 0.2338 - val_acc: 0.9196\n",
            "Epoch 152/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1519 - acc: 0.9376 - val_loss: 0.2297 - val_acc: 0.9107\n",
            "Epoch 153/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1562 - acc: 0.9577 - val_loss: 0.2293 - val_acc: 0.9196\n",
            "Epoch 154/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1736 - acc: 0.9421 - val_loss: 0.2341 - val_acc: 0.9286\n",
            "Epoch 155/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1548 - acc: 0.9421 - val_loss: 0.2320 - val_acc: 0.9196\n",
            "Epoch 156/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1263 - acc: 0.9599 - val_loss: 0.2306 - val_acc: 0.9107\n",
            "Epoch 157/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1255 - acc: 0.9666 - val_loss: 0.2295 - val_acc: 0.9107\n",
            "Epoch 158/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1433 - acc: 0.9621 - val_loss: 0.2330 - val_acc: 0.9286\n",
            "Epoch 159/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1428 - acc: 0.9621 - val_loss: 0.2318 - val_acc: 0.9375\n",
            "Epoch 160/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1982 - acc: 0.9488 - val_loss: 0.2453 - val_acc: 0.9286\n",
            "Epoch 161/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2211 - acc: 0.9555 - val_loss: 0.2432 - val_acc: 0.9375\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2432 - acc: 0.9375\n",
            "Accuracy: : 93.75%\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                63424     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 32)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "15/15 [==============================] - 1s 22ms/step - loss: 0.6824 - acc: 0.5991 - val_loss: 0.6764 - val_acc: 0.5982\n",
            "Epoch 2/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6754 - acc: 0.5991 - val_loss: 0.6704 - val_acc: 0.5982\n",
            "Epoch 3/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6763 - acc: 0.5969 - val_loss: 0.6678 - val_acc: 0.5982\n",
            "Epoch 4/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6698 - acc: 0.5947 - val_loss: 0.6671 - val_acc: 0.5982\n",
            "Epoch 5/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6704 - acc: 0.5991 - val_loss: 0.6643 - val_acc: 0.5982\n",
            "Epoch 6/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6684 - acc: 0.5969 - val_loss: 0.6612 - val_acc: 0.5982\n",
            "Epoch 7/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6689 - acc: 0.5969 - val_loss: 0.6581 - val_acc: 0.5982\n",
            "Epoch 8/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6652 - acc: 0.5947 - val_loss: 0.6549 - val_acc: 0.5982\n",
            "Epoch 9/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6644 - acc: 0.5969 - val_loss: 0.6519 - val_acc: 0.5982\n",
            "Epoch 10/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6609 - acc: 0.5969 - val_loss: 0.6474 - val_acc: 0.5982\n",
            "Epoch 11/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.5969 - val_loss: 0.6437 - val_acc: 0.5982\n",
            "Epoch 12/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6510 - acc: 0.5969 - val_loss: 0.6404 - val_acc: 0.5982\n",
            "Epoch 13/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6451 - acc: 0.6013 - val_loss: 0.6334 - val_acc: 0.5982\n",
            "Epoch 14/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6460 - acc: 0.5969 - val_loss: 0.6271 - val_acc: 0.5982\n",
            "Epoch 15/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6362 - acc: 0.6192 - val_loss: 0.6203 - val_acc: 0.6071\n",
            "Epoch 16/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6254 - acc: 0.6102 - val_loss: 0.6181 - val_acc: 0.5982\n",
            "Epoch 17/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6304 - acc: 0.6013 - val_loss: 0.6069 - val_acc: 0.6071\n",
            "Epoch 18/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6314 - acc: 0.6325 - val_loss: 0.5977 - val_acc: 0.6161\n",
            "Epoch 19/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6179 - acc: 0.6526 - val_loss: 0.5910 - val_acc: 0.6875\n",
            "Epoch 20/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6095 - acc: 0.6615 - val_loss: 0.5800 - val_acc: 0.6875\n",
            "Epoch 21/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5922 - acc: 0.6815 - val_loss: 0.5668 - val_acc: 0.7411\n",
            "Epoch 22/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5853 - acc: 0.6860 - val_loss: 0.5563 - val_acc: 0.7411\n",
            "Epoch 23/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5872 - acc: 0.6704 - val_loss: 0.5476 - val_acc: 0.7679\n",
            "Epoch 24/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5904 - acc: 0.6882 - val_loss: 0.5375 - val_acc: 0.8036\n",
            "Epoch 25/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5709 - acc: 0.7060 - val_loss: 0.5237 - val_acc: 0.7857\n",
            "Epoch 26/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5667 - acc: 0.7439 - val_loss: 0.5171 - val_acc: 0.8571\n",
            "Epoch 27/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5530 - acc: 0.7528 - val_loss: 0.4998 - val_acc: 0.7946\n",
            "Epoch 28/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5376 - acc: 0.7394 - val_loss: 0.4865 - val_acc: 0.8571\n",
            "Epoch 29/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5290 - acc: 0.7840 - val_loss: 0.4746 - val_acc: 0.8750\n",
            "Epoch 30/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5214 - acc: 0.7439 - val_loss: 0.4695 - val_acc: 0.8571\n",
            "Epoch 31/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4899 - acc: 0.7862 - val_loss: 0.4466 - val_acc: 0.8304\n",
            "Epoch 32/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5010 - acc: 0.7661 - val_loss: 0.4504 - val_acc: 0.8839\n",
            "Epoch 33/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5105 - acc: 0.7795 - val_loss: 0.4500 - val_acc: 0.8393\n",
            "Epoch 34/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4915 - acc: 0.7506 - val_loss: 0.4223 - val_acc: 0.8750\n",
            "Epoch 35/400\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.4682 - acc: 0.8552 - val_loss: 0.4115 - val_acc: 0.9018\n",
            "Epoch 36/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4505 - acc: 0.8129 - val_loss: 0.3959 - val_acc: 0.8839\n",
            "Epoch 37/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4449 - acc: 0.8285 - val_loss: 0.3955 - val_acc: 0.9107\n",
            "Epoch 38/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4191 - acc: 0.8775 - val_loss: 0.3710 - val_acc: 0.9018\n",
            "Epoch 39/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4165 - acc: 0.8419 - val_loss: 0.3678 - val_acc: 0.9107\n",
            "Epoch 40/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4166 - acc: 0.8753 - val_loss: 0.3526 - val_acc: 0.8750\n",
            "Epoch 41/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3997 - acc: 0.8530 - val_loss: 0.3513 - val_acc: 0.9286\n",
            "Epoch 42/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3768 - acc: 0.8864 - val_loss: 0.3288 - val_acc: 0.9018\n",
            "Epoch 43/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4198 - acc: 0.8508 - val_loss: 0.3543 - val_acc: 0.9375\n",
            "Epoch 44/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3971 - acc: 0.8619 - val_loss: 0.3131 - val_acc: 0.9375\n",
            "Epoch 45/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3720 - acc: 0.8909 - val_loss: 0.3211 - val_acc: 0.8929\n",
            "Epoch 46/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3750 - acc: 0.8530 - val_loss: 0.3019 - val_acc: 0.9286\n",
            "Epoch 47/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3465 - acc: 0.8931 - val_loss: 0.2860 - val_acc: 0.9196\n",
            "Epoch 48/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3450 - acc: 0.8842 - val_loss: 0.2799 - val_acc: 0.9286\n",
            "Epoch 49/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3278 - acc: 0.9087 - val_loss: 0.2732 - val_acc: 0.9375\n",
            "Epoch 50/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 0.8953 - val_loss: 0.2665 - val_acc: 0.9286\n",
            "Epoch 51/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3125 - acc: 0.9065 - val_loss: 0.2551 - val_acc: 0.9464\n",
            "Epoch 52/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2911 - acc: 0.9176 - val_loss: 0.2484 - val_acc: 0.9375\n",
            "Epoch 53/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2913 - acc: 0.9109 - val_loss: 0.2474 - val_acc: 0.9464\n",
            "Epoch 54/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3275 - acc: 0.8886 - val_loss: 0.2476 - val_acc: 0.9286\n",
            "Epoch 55/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3124 - acc: 0.8998 - val_loss: 0.2387 - val_acc: 0.9286\n",
            "Epoch 56/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2877 - acc: 0.9131 - val_loss: 0.2318 - val_acc: 0.9464\n",
            "Epoch 57/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2877 - acc: 0.9042 - val_loss: 0.2287 - val_acc: 0.9375\n",
            "Epoch 58/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2733 - acc: 0.9065 - val_loss: 0.2172 - val_acc: 0.9464\n",
            "Epoch 59/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2835 - acc: 0.9131 - val_loss: 0.2214 - val_acc: 0.9286\n",
            "Epoch 60/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2623 - acc: 0.9287 - val_loss: 0.2189 - val_acc: 0.9375\n",
            "Epoch 61/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2754 - acc: 0.9087 - val_loss: 0.2205 - val_acc: 0.9286\n",
            "Epoch 62/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2636 - acc: 0.9176 - val_loss: 0.2025 - val_acc: 0.9464\n",
            "Epoch 63/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2605 - acc: 0.9154 - val_loss: 0.1985 - val_acc: 0.9464\n",
            "Epoch 64/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2493 - acc: 0.9243 - val_loss: 0.1943 - val_acc: 0.9464\n",
            "Epoch 65/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2465 - acc: 0.9310 - val_loss: 0.1888 - val_acc: 0.9464\n",
            "Epoch 66/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2364 - acc: 0.9332 - val_loss: 0.1878 - val_acc: 0.9375\n",
            "Epoch 67/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2118 - acc: 0.9443 - val_loss: 0.1956 - val_acc: 0.9375\n",
            "Epoch 68/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2450 - acc: 0.9176 - val_loss: 0.1825 - val_acc: 0.9554\n",
            "Epoch 69/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2247 - acc: 0.9310 - val_loss: 0.1880 - val_acc: 0.9375\n",
            "Epoch 70/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2178 - acc: 0.9332 - val_loss: 0.1757 - val_acc: 0.9554\n",
            "Epoch 71/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2424 - acc: 0.9376 - val_loss: 0.1677 - val_acc: 0.9554\n",
            "Epoch 72/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2113 - acc: 0.9265 - val_loss: 0.1680 - val_acc: 0.9554\n",
            "Epoch 73/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2177 - acc: 0.9243 - val_loss: 0.1631 - val_acc: 0.9554\n",
            "Epoch 74/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2129 - acc: 0.9376 - val_loss: 0.1606 - val_acc: 0.9554\n",
            "Epoch 75/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2084 - acc: 0.9421 - val_loss: 0.1629 - val_acc: 0.9464\n",
            "Epoch 76/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1973 - acc: 0.9421 - val_loss: 0.1555 - val_acc: 0.9643\n",
            "Epoch 77/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1975 - acc: 0.9376 - val_loss: 0.1521 - val_acc: 0.9554\n",
            "Epoch 78/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1973 - acc: 0.9399 - val_loss: 0.1660 - val_acc: 0.9464\n",
            "Epoch 79/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1953 - acc: 0.9465 - val_loss: 0.1535 - val_acc: 0.9643\n",
            "Epoch 80/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1872 - acc: 0.9510 - val_loss: 0.1614 - val_acc: 0.9464\n",
            "Epoch 81/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2042 - acc: 0.9376 - val_loss: 0.1532 - val_acc: 0.9554\n",
            "Epoch 82/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2112 - acc: 0.9287 - val_loss: 0.1588 - val_acc: 0.9554\n",
            "Epoch 83/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1929 - acc: 0.9555 - val_loss: 0.1459 - val_acc: 0.9643\n",
            "Epoch 84/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1659 - acc: 0.9577 - val_loss: 0.1561 - val_acc: 0.9554\n",
            "Epoch 85/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1855 - acc: 0.9555 - val_loss: 0.1381 - val_acc: 0.9554\n",
            "Epoch 86/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1726 - acc: 0.9644 - val_loss: 0.1422 - val_acc: 0.9643\n",
            "Epoch 87/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1455 - acc: 0.9621 - val_loss: 0.1325 - val_acc: 0.9554\n",
            "Epoch 88/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1762 - acc: 0.9510 - val_loss: 0.1386 - val_acc: 0.9643\n",
            "Epoch 89/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1663 - acc: 0.9621 - val_loss: 0.1360 - val_acc: 0.9643\n",
            "Epoch 90/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1655 - acc: 0.9510 - val_loss: 0.1312 - val_acc: 0.9554\n",
            "Epoch 91/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1738 - acc: 0.9510 - val_loss: 0.1275 - val_acc: 0.9554\n",
            "Epoch 92/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1555 - acc: 0.9577 - val_loss: 0.1387 - val_acc: 0.9643\n",
            "Epoch 93/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1803 - acc: 0.9421 - val_loss: 0.1435 - val_acc: 0.9643\n",
            "Epoch 94/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1637 - acc: 0.9488 - val_loss: 0.1245 - val_acc: 0.9554\n",
            "Epoch 95/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1628 - acc: 0.9577 - val_loss: 0.1224 - val_acc: 0.9554\n",
            "Epoch 96/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1755 - acc: 0.9354 - val_loss: 0.1506 - val_acc: 0.9554\n",
            "Epoch 97/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1494 - acc: 0.9577 - val_loss: 0.1215 - val_acc: 0.9554\n",
            "Epoch 98/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2290 - acc: 0.9243 - val_loss: 0.1767 - val_acc: 0.9286\n",
            "Epoch 99/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1596 - acc: 0.9532 - val_loss: 0.1213 - val_acc: 0.9554\n",
            "Epoch 100/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1440 - acc: 0.9644 - val_loss: 0.1267 - val_acc: 0.9554\n",
            "Epoch 101/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1382 - acc: 0.9532 - val_loss: 0.1187 - val_acc: 0.9554\n",
            "Epoch 102/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1308 - acc: 0.9644 - val_loss: 0.1290 - val_acc: 0.9643\n",
            "Epoch 103/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1380 - acc: 0.9621 - val_loss: 0.1234 - val_acc: 0.9554\n",
            "Epoch 104/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1352 - acc: 0.9710 - val_loss: 0.1263 - val_acc: 0.9643\n",
            "Epoch 105/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1400 - acc: 0.9621 - val_loss: 0.1185 - val_acc: 0.9554\n",
            "Epoch 106/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1385 - acc: 0.9688 - val_loss: 0.1330 - val_acc: 0.9643\n",
            "Epoch 107/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1546 - acc: 0.9577 - val_loss: 0.1297 - val_acc: 0.9643\n",
            "Epoch 108/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1505 - acc: 0.9532 - val_loss: 0.1192 - val_acc: 0.9554\n",
            "Epoch 109/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1297 - acc: 0.9644 - val_loss: 0.1230 - val_acc: 0.9554\n",
            "Epoch 110/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1333 - acc: 0.9644 - val_loss: 0.1150 - val_acc: 0.9554\n",
            "Epoch 111/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1267 - acc: 0.9688 - val_loss: 0.1203 - val_acc: 0.9554\n",
            "Epoch 112/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1225 - acc: 0.9688 - val_loss: 0.1152 - val_acc: 0.9554\n",
            "Epoch 113/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1496 - acc: 0.9666 - val_loss: 0.1082 - val_acc: 0.9554\n",
            "Epoch 114/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1228 - acc: 0.9644 - val_loss: 0.1420 - val_acc: 0.9464\n",
            "Epoch 115/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1192 - acc: 0.9710 - val_loss: 0.1098 - val_acc: 0.9554\n",
            "Epoch 116/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1389 - acc: 0.9577 - val_loss: 0.1121 - val_acc: 0.9554\n",
            "Epoch 117/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1487 - acc: 0.9666 - val_loss: 0.1361 - val_acc: 0.9464\n",
            "Epoch 118/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1193 - acc: 0.9688 - val_loss: 0.1108 - val_acc: 0.9554\n",
            "Epoch 119/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1193 - acc: 0.9710 - val_loss: 0.1090 - val_acc: 0.9554\n",
            "Epoch 120/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1172 - acc: 0.9644 - val_loss: 0.1332 - val_acc: 0.9464\n",
            "Epoch 121/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1277 - acc: 0.9644 - val_loss: 0.1182 - val_acc: 0.9554\n",
            "Epoch 122/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1310 - acc: 0.9621 - val_loss: 0.1071 - val_acc: 0.9554\n",
            "Epoch 123/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1317 - acc: 0.9688 - val_loss: 0.1076 - val_acc: 0.9554\n",
            "Epoch 124/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1272 - acc: 0.9777 - val_loss: 0.1144 - val_acc: 0.9554\n",
            "Epoch 125/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1049 - acc: 0.9800 - val_loss: 0.1093 - val_acc: 0.9554\n",
            "Epoch 126/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1200 - acc: 0.9733 - val_loss: 0.1073 - val_acc: 0.9554\n",
            "Epoch 127/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1507 - acc: 0.9599 - val_loss: 0.1146 - val_acc: 0.9554\n",
            "Epoch 128/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1151 - acc: 0.9666 - val_loss: 0.1064 - val_acc: 0.9554\n",
            "Epoch 129/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1155 - acc: 0.9822 - val_loss: 0.1239 - val_acc: 0.9643\n",
            "Epoch 130/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1165 - acc: 0.9710 - val_loss: 0.1092 - val_acc: 0.9554\n",
            "Epoch 131/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1010 - acc: 0.9733 - val_loss: 0.1103 - val_acc: 0.9554\n",
            "Epoch 132/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0936 - acc: 0.9733 - val_loss: 0.1089 - val_acc: 0.9554\n",
            "Epoch 133/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1077 - acc: 0.9800 - val_loss: 0.1128 - val_acc: 0.9554\n",
            "Epoch 134/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0923 - acc: 0.9800 - val_loss: 0.1215 - val_acc: 0.9643\n",
            "Epoch 135/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1017 - acc: 0.9800 - val_loss: 0.1058 - val_acc: 0.9643\n",
            "Epoch 136/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1350 - acc: 0.9733 - val_loss: 0.1471 - val_acc: 0.9464\n",
            "Epoch 137/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1122 - acc: 0.9688 - val_loss: 0.1110 - val_acc: 0.9554\n",
            "Epoch 138/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1083 - acc: 0.9755 - val_loss: 0.1112 - val_acc: 0.9554\n",
            "Epoch 139/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1044 - acc: 0.9733 - val_loss: 0.1141 - val_acc: 0.9554\n",
            "Epoch 140/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1098 - acc: 0.9688 - val_loss: 0.1223 - val_acc: 0.9643\n",
            "Epoch 141/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0840 - acc: 0.9866 - val_loss: 0.1034 - val_acc: 0.9554\n",
            "Epoch 142/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0842 - acc: 0.9755 - val_loss: 0.1164 - val_acc: 0.9643\n",
            "Epoch 143/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0975 - acc: 0.9822 - val_loss: 0.1034 - val_acc: 0.9554\n",
            "Epoch 144/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0929 - acc: 0.9800 - val_loss: 0.1177 - val_acc: 0.9554\n",
            "Epoch 145/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0940 - acc: 0.9822 - val_loss: 0.1070 - val_acc: 0.9554\n",
            "Epoch 146/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0898 - acc: 0.9777 - val_loss: 0.1223 - val_acc: 0.9643\n",
            "Epoch 147/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0896 - acc: 0.9822 - val_loss: 0.1106 - val_acc: 0.9554\n",
            "Epoch 148/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0822 - acc: 0.9800 - val_loss: 0.1208 - val_acc: 0.9643\n",
            "Epoch 149/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0889 - acc: 0.9844 - val_loss: 0.1071 - val_acc: 0.9554\n",
            "Epoch 150/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0720 - acc: 0.9889 - val_loss: 0.1344 - val_acc: 0.9464\n",
            "Epoch 151/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1342 - acc: 0.9599 - val_loss: 0.1005 - val_acc: 0.9554\n",
            "Epoch 152/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1064 - acc: 0.9755 - val_loss: 0.1316 - val_acc: 0.9554\n",
            "Epoch 153/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0798 - acc: 0.9911 - val_loss: 0.1125 - val_acc: 0.9554\n",
            "Epoch 154/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0813 - acc: 0.9844 - val_loss: 0.1202 - val_acc: 0.9643\n",
            "Epoch 155/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0817 - acc: 0.9822 - val_loss: 0.1244 - val_acc: 0.9554\n",
            "Epoch 156/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0765 - acc: 0.9866 - val_loss: 0.1067 - val_acc: 0.9554\n",
            "Epoch 157/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0900 - acc: 0.9866 - val_loss: 0.1108 - val_acc: 0.9554\n",
            "Epoch 158/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0870 - acc: 0.9822 - val_loss: 0.1188 - val_acc: 0.9643\n",
            "Epoch 159/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0826 - acc: 0.9800 - val_loss: 0.1049 - val_acc: 0.9554\n",
            "Epoch 160/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0932 - acc: 0.9844 - val_loss: 0.1302 - val_acc: 0.9554\n",
            "Epoch 161/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0979 - acc: 0.9777 - val_loss: 0.1062 - val_acc: 0.9554\n",
            "Epoch 162/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0824 - acc: 0.9777 - val_loss: 0.1328 - val_acc: 0.9554\n",
            "Epoch 163/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0870 - acc: 0.9800 - val_loss: 0.1089 - val_acc: 0.9554\n",
            "Epoch 164/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0701 - acc: 0.9822 - val_loss: 0.1242 - val_acc: 0.9643\n",
            "Epoch 165/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0830 - acc: 0.9822 - val_loss: 0.1060 - val_acc: 0.9464\n",
            "Epoch 166/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0811 - acc: 0.9822 - val_loss: 0.1191 - val_acc: 0.9643\n",
            "Epoch 167/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0656 - acc: 0.9844 - val_loss: 0.1066 - val_acc: 0.9554\n",
            "Epoch 168/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0799 - acc: 0.9866 - val_loss: 0.1117 - val_acc: 0.9554\n",
            "Epoch 169/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0695 - acc: 0.9889 - val_loss: 0.1122 - val_acc: 0.9554\n",
            "Epoch 170/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0982 - acc: 0.9777 - val_loss: 0.1079 - val_acc: 0.9464\n",
            "Epoch 171/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0629 - acc: 0.9911 - val_loss: 0.1257 - val_acc: 0.9643\n",
            "Epoch 172/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1105 - acc: 0.9755 - val_loss: 0.1013 - val_acc: 0.9643\n",
            "Epoch 173/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0808 - acc: 0.9844 - val_loss: 0.1153 - val_acc: 0.9554\n",
            "Epoch 174/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0763 - acc: 0.9755 - val_loss: 0.1217 - val_acc: 0.9643\n",
            "Epoch 175/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0720 - acc: 0.9800 - val_loss: 0.1069 - val_acc: 0.9464\n",
            "Epoch 176/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0888 - acc: 0.9822 - val_loss: 0.1292 - val_acc: 0.9554\n",
            "Epoch 177/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0659 - acc: 0.9800 - val_loss: 0.1083 - val_acc: 0.9464\n",
            "Epoch 178/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0722 - acc: 0.9822 - val_loss: 0.1161 - val_acc: 0.9554\n",
            "Epoch 179/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0810 - acc: 0.9822 - val_loss: 0.1112 - val_acc: 0.9554\n",
            "Epoch 180/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0884 - acc: 0.9777 - val_loss: 0.1075 - val_acc: 0.9464\n",
            "Epoch 181/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0689 - acc: 0.9800 - val_loss: 0.1106 - val_acc: 0.9554\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1106 - acc: 0.9554\n",
            "Accuracy: : 95.54%\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 64)                63424     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 32)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "15/15 [==============================] - 1s 20ms/step - loss: 0.6962 - acc: 0.4499 - val_loss: 0.6908 - val_acc: 0.5982\n",
            "Epoch 2/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6909 - acc: 0.5568 - val_loss: 0.6877 - val_acc: 0.5982\n",
            "Epoch 3/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6869 - acc: 0.5991 - val_loss: 0.6849 - val_acc: 0.5982\n",
            "Epoch 4/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6822 - acc: 0.5991 - val_loss: 0.6812 - val_acc: 0.5982\n",
            "Epoch 5/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6824 - acc: 0.5947 - val_loss: 0.6779 - val_acc: 0.5982\n",
            "Epoch 6/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6796 - acc: 0.5969 - val_loss: 0.6762 - val_acc: 0.5982\n",
            "Epoch 7/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6811 - acc: 0.5969 - val_loss: 0.6767 - val_acc: 0.5982\n",
            "Epoch 8/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6826 - acc: 0.5947 - val_loss: 0.6772 - val_acc: 0.5982\n",
            "Epoch 9/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6794 - acc: 0.5947 - val_loss: 0.6766 - val_acc: 0.5982\n",
            "Epoch 10/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6733 - acc: 0.5991 - val_loss: 0.6731 - val_acc: 0.5982\n",
            "Epoch 11/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6709 - acc: 0.5969 - val_loss: 0.6707 - val_acc: 0.5982\n",
            "Epoch 12/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6736 - acc: 0.5969 - val_loss: 0.6685 - val_acc: 0.5982\n",
            "Epoch 13/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6715 - acc: 0.5991 - val_loss: 0.6674 - val_acc: 0.5982\n",
            "Epoch 14/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.5969 - val_loss: 0.6644 - val_acc: 0.5982\n",
            "Epoch 15/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6662 - acc: 0.5991 - val_loss: 0.6613 - val_acc: 0.5982\n",
            "Epoch 16/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6633 - acc: 0.5969 - val_loss: 0.6578 - val_acc: 0.5982\n",
            "Epoch 17/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6605 - acc: 0.5991 - val_loss: 0.6548 - val_acc: 0.5982\n",
            "Epoch 18/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6517 - acc: 0.5969 - val_loss: 0.6523 - val_acc: 0.5982\n",
            "Epoch 19/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6515 - acc: 0.6347 - val_loss: 0.6506 - val_acc: 0.5982\n",
            "Epoch 20/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6469 - acc: 0.6147 - val_loss: 0.6434 - val_acc: 0.5982\n",
            "Epoch 21/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6441 - acc: 0.6080 - val_loss: 0.6397 - val_acc: 0.5982\n",
            "Epoch 22/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6417 - acc: 0.6437 - val_loss: 0.6334 - val_acc: 0.6071\n",
            "Epoch 23/400\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.6310 - acc: 0.6570 - val_loss: 0.6250 - val_acc: 0.6964\n",
            "Epoch 24/400\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.6298 - acc: 0.6704 - val_loss: 0.6176 - val_acc: 0.7143\n",
            "Epoch 25/400\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.6213 - acc: 0.6748 - val_loss: 0.6147 - val_acc: 0.6161\n",
            "Epoch 26/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6091 - acc: 0.6748 - val_loss: 0.6014 - val_acc: 0.7143\n",
            "Epoch 27/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6047 - acc: 0.6837 - val_loss: 0.5908 - val_acc: 0.7679\n",
            "Epoch 28/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5864 - acc: 0.7127 - val_loss: 0.5772 - val_acc: 0.7768\n",
            "Epoch 29/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5804 - acc: 0.7038 - val_loss: 0.5706 - val_acc: 0.7768\n",
            "Epoch 30/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5632 - acc: 0.7461 - val_loss: 0.5610 - val_acc: 0.7946\n",
            "Epoch 31/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5736 - acc: 0.7305 - val_loss: 0.5467 - val_acc: 0.7857\n",
            "Epoch 32/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5549 - acc: 0.7372 - val_loss: 0.5389 - val_acc: 0.7946\n",
            "Epoch 33/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5455 - acc: 0.7305 - val_loss: 0.5272 - val_acc: 0.8036\n",
            "Epoch 34/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5339 - acc: 0.7528 - val_loss: 0.5120 - val_acc: 0.8036\n",
            "Epoch 35/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5163 - acc: 0.7773 - val_loss: 0.5065 - val_acc: 0.8214\n",
            "Epoch 36/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4945 - acc: 0.8040 - val_loss: 0.4910 - val_acc: 0.7946\n",
            "Epoch 37/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5087 - acc: 0.7728 - val_loss: 0.4852 - val_acc: 0.7857\n",
            "Epoch 38/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5058 - acc: 0.7906 - val_loss: 0.4747 - val_acc: 0.8214\n",
            "Epoch 39/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4976 - acc: 0.7550 - val_loss: 0.4677 - val_acc: 0.8304\n",
            "Epoch 40/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4712 - acc: 0.7929 - val_loss: 0.4590 - val_acc: 0.8036\n",
            "Epoch 41/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4612 - acc: 0.8241 - val_loss: 0.4437 - val_acc: 0.8304\n",
            "Epoch 42/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4358 - acc: 0.8151 - val_loss: 0.4330 - val_acc: 0.8036\n",
            "Epoch 43/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4509 - acc: 0.8129 - val_loss: 0.4253 - val_acc: 0.8214\n",
            "Epoch 44/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4809 - acc: 0.7862 - val_loss: 0.4315 - val_acc: 0.8125\n",
            "Epoch 45/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4207 - acc: 0.8396 - val_loss: 0.4157 - val_acc: 0.8393\n",
            "Epoch 46/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3991 - acc: 0.8575 - val_loss: 0.3995 - val_acc: 0.8482\n",
            "Epoch 47/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3984 - acc: 0.8463 - val_loss: 0.3937 - val_acc: 0.8482\n",
            "Epoch 48/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3709 - acc: 0.8753 - val_loss: 0.3934 - val_acc: 0.8304\n",
            "Epoch 49/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4383 - acc: 0.8107 - val_loss: 0.3829 - val_acc: 0.8482\n",
            "Epoch 50/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3929 - acc: 0.8396 - val_loss: 0.3690 - val_acc: 0.8571\n",
            "Epoch 51/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3702 - acc: 0.8686 - val_loss: 0.3696 - val_acc: 0.8571\n",
            "Epoch 52/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3407 - acc: 0.8664 - val_loss: 0.3535 - val_acc: 0.8482\n",
            "Epoch 53/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3643 - acc: 0.8597 - val_loss: 0.3563 - val_acc: 0.8661\n",
            "Epoch 54/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3373 - acc: 0.8731 - val_loss: 0.3390 - val_acc: 0.8571\n",
            "Epoch 55/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3348 - acc: 0.8864 - val_loss: 0.3315 - val_acc: 0.8661\n",
            "Epoch 56/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3310 - acc: 0.8909 - val_loss: 0.3261 - val_acc: 0.8661\n",
            "Epoch 57/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3333 - acc: 0.8886 - val_loss: 0.3238 - val_acc: 0.8750\n",
            "Epoch 58/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3335 - acc: 0.8731 - val_loss: 0.3282 - val_acc: 0.8839\n",
            "Epoch 59/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2923 - acc: 0.9020 - val_loss: 0.3199 - val_acc: 0.8839\n",
            "Epoch 60/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3184 - acc: 0.8998 - val_loss: 0.3041 - val_acc: 0.8661\n",
            "Epoch 61/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2936 - acc: 0.8931 - val_loss: 0.2994 - val_acc: 0.8750\n",
            "Epoch 62/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2840 - acc: 0.9109 - val_loss: 0.2926 - val_acc: 0.8661\n",
            "Epoch 63/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2773 - acc: 0.9087 - val_loss: 0.3063 - val_acc: 0.8839\n",
            "Epoch 64/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3641 - acc: 0.8886 - val_loss: 0.3043 - val_acc: 0.8839\n",
            "Epoch 65/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2701 - acc: 0.9154 - val_loss: 0.2833 - val_acc: 0.8839\n",
            "Epoch 66/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2753 - acc: 0.9020 - val_loss: 0.2777 - val_acc: 0.8839\n",
            "Epoch 67/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2613 - acc: 0.9131 - val_loss: 0.2769 - val_acc: 0.8839\n",
            "Epoch 68/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2708 - acc: 0.9065 - val_loss: 0.2814 - val_acc: 0.8839\n",
            "Epoch 69/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2874 - acc: 0.8931 - val_loss: 0.2883 - val_acc: 0.8839\n",
            "Epoch 70/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2798 - acc: 0.8864 - val_loss: 0.2668 - val_acc: 0.8929\n",
            "Epoch 71/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2512 - acc: 0.9220 - val_loss: 0.2657 - val_acc: 0.8750\n",
            "Epoch 72/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2574 - acc: 0.9020 - val_loss: 0.2620 - val_acc: 0.8929\n",
            "Epoch 73/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2482 - acc: 0.9154 - val_loss: 0.2612 - val_acc: 0.8839\n",
            "Epoch 74/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2376 - acc: 0.9287 - val_loss: 0.2559 - val_acc: 0.8839\n",
            "Epoch 75/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2668 - acc: 0.9220 - val_loss: 0.2662 - val_acc: 0.8929\n",
            "Epoch 76/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3575 - acc: 0.8374 - val_loss: 0.2734 - val_acc: 0.8839\n",
            "Epoch 77/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2959 - acc: 0.8931 - val_loss: 0.2539 - val_acc: 0.8839\n",
            "Epoch 78/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2357 - acc: 0.9287 - val_loss: 0.2509 - val_acc: 0.8839\n",
            "Epoch 79/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2521 - acc: 0.9154 - val_loss: 0.2486 - val_acc: 0.8839\n",
            "Epoch 80/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2362 - acc: 0.9287 - val_loss: 0.2479 - val_acc: 0.8839\n",
            "Epoch 81/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2155 - acc: 0.9421 - val_loss: 0.2456 - val_acc: 0.8839\n",
            "Epoch 82/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2471 - acc: 0.9421 - val_loss: 0.2420 - val_acc: 0.8750\n",
            "Epoch 83/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2161 - acc: 0.9265 - val_loss: 0.2405 - val_acc: 0.8750\n",
            "Epoch 84/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2256 - acc: 0.9376 - val_loss: 0.2390 - val_acc: 0.8929\n",
            "Epoch 85/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2122 - acc: 0.9443 - val_loss: 0.2372 - val_acc: 0.8750\n",
            "Epoch 86/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2217 - acc: 0.9198 - val_loss: 0.2336 - val_acc: 0.8929\n",
            "Epoch 87/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2040 - acc: 0.9354 - val_loss: 0.2313 - val_acc: 0.8750\n",
            "Epoch 88/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2094 - acc: 0.9243 - val_loss: 0.2367 - val_acc: 0.9018\n",
            "Epoch 89/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2321 - acc: 0.9332 - val_loss: 0.2313 - val_acc: 0.8929\n",
            "Epoch 90/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2151 - acc: 0.9332 - val_loss: 0.2305 - val_acc: 0.8929\n",
            "Epoch 91/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1865 - acc: 0.9488 - val_loss: 0.2252 - val_acc: 0.8929\n",
            "Epoch 92/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2060 - acc: 0.9421 - val_loss: 0.2255 - val_acc: 0.8929\n",
            "Epoch 93/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1960 - acc: 0.9287 - val_loss: 0.2238 - val_acc: 0.8929\n",
            "Epoch 94/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2100 - acc: 0.9421 - val_loss: 0.2265 - val_acc: 0.8750\n",
            "Epoch 95/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1937 - acc: 0.9332 - val_loss: 0.2216 - val_acc: 0.9018\n",
            "Epoch 96/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2030 - acc: 0.9176 - val_loss: 0.2188 - val_acc: 0.8750\n",
            "Epoch 97/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1760 - acc: 0.9399 - val_loss: 0.2216 - val_acc: 0.9018\n",
            "Epoch 98/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1768 - acc: 0.9443 - val_loss: 0.2143 - val_acc: 0.8929\n",
            "Epoch 99/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1954 - acc: 0.9488 - val_loss: 0.2143 - val_acc: 0.8929\n",
            "Epoch 100/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1877 - acc: 0.9354 - val_loss: 0.2116 - val_acc: 0.8929\n",
            "Epoch 101/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1970 - acc: 0.9488 - val_loss: 0.2076 - val_acc: 0.8839\n",
            "Epoch 102/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1915 - acc: 0.9310 - val_loss: 0.2064 - val_acc: 0.8929\n",
            "Epoch 103/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1914 - acc: 0.9332 - val_loss: 0.2027 - val_acc: 0.8929\n",
            "Epoch 104/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1704 - acc: 0.9443 - val_loss: 0.2197 - val_acc: 0.8929\n",
            "Epoch 105/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2556 - acc: 0.8976 - val_loss: 0.2198 - val_acc: 0.8839\n",
            "Epoch 106/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2437 - acc: 0.9020 - val_loss: 0.2199 - val_acc: 0.8929\n",
            "Epoch 107/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1980 - acc: 0.9354 - val_loss: 0.2098 - val_acc: 0.8839\n",
            "Epoch 108/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1771 - acc: 0.9488 - val_loss: 0.2093 - val_acc: 0.9107\n",
            "Epoch 109/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1855 - acc: 0.9376 - val_loss: 0.2067 - val_acc: 0.9107\n",
            "Epoch 110/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2058 - acc: 0.9332 - val_loss: 0.2008 - val_acc: 0.9018\n",
            "Epoch 111/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1857 - acc: 0.9488 - val_loss: 0.1983 - val_acc: 0.8839\n",
            "Epoch 112/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1774 - acc: 0.9443 - val_loss: 0.1988 - val_acc: 0.8929\n",
            "Epoch 113/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1636 - acc: 0.9488 - val_loss: 0.1950 - val_acc: 0.9107\n",
            "Epoch 114/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1866 - acc: 0.9510 - val_loss: 0.1962 - val_acc: 0.9107\n",
            "Epoch 115/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1730 - acc: 0.9488 - val_loss: 0.1909 - val_acc: 0.9107\n",
            "Epoch 116/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1571 - acc: 0.9510 - val_loss: 0.1911 - val_acc: 0.9107\n",
            "Epoch 117/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1671 - acc: 0.9555 - val_loss: 0.1895 - val_acc: 0.9107\n",
            "Epoch 118/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1609 - acc: 0.9555 - val_loss: 0.1868 - val_acc: 0.9018\n",
            "Epoch 119/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1453 - acc: 0.9577 - val_loss: 0.1958 - val_acc: 0.9107\n",
            "Epoch 120/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2745 - acc: 0.8976 - val_loss: 0.2013 - val_acc: 0.9196\n",
            "Epoch 121/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2592 - acc: 0.8976 - val_loss: 0.2031 - val_acc: 0.9107\n",
            "Epoch 122/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2032 - acc: 0.9265 - val_loss: 0.1900 - val_acc: 0.9107\n",
            "Epoch 123/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1856 - acc: 0.9443 - val_loss: 0.1895 - val_acc: 0.9107\n",
            "Epoch 124/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1755 - acc: 0.9532 - val_loss: 0.1867 - val_acc: 0.9018\n",
            "Epoch 125/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1486 - acc: 0.9710 - val_loss: 0.1842 - val_acc: 0.9018\n",
            "Epoch 126/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1403 - acc: 0.9666 - val_loss: 0.1854 - val_acc: 0.9107\n",
            "Epoch 127/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1268 - acc: 0.9666 - val_loss: 0.1873 - val_acc: 0.9196\n",
            "Epoch 128/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1504 - acc: 0.9510 - val_loss: 0.1847 - val_acc: 0.9196\n",
            "Epoch 129/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1636 - acc: 0.9599 - val_loss: 0.1784 - val_acc: 0.9107\n",
            "Epoch 130/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1548 - acc: 0.9599 - val_loss: 0.1756 - val_acc: 0.9107\n",
            "Epoch 131/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1656 - acc: 0.9510 - val_loss: 0.1717 - val_acc: 0.9196\n",
            "Epoch 132/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1662 - acc: 0.9621 - val_loss: 0.1676 - val_acc: 0.9107\n",
            "Epoch 133/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1564 - acc: 0.9577 - val_loss: 0.1712 - val_acc: 0.9196\n",
            "Epoch 134/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1449 - acc: 0.9532 - val_loss: 0.1680 - val_acc: 0.9286\n",
            "Epoch 135/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1320 - acc: 0.9532 - val_loss: 0.1662 - val_acc: 0.9286\n",
            "Epoch 136/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1401 - acc: 0.9644 - val_loss: 0.1662 - val_acc: 0.9107\n",
            "Epoch 137/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1465 - acc: 0.9688 - val_loss: 0.1645 - val_acc: 0.9196\n",
            "Epoch 138/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1448 - acc: 0.9688 - val_loss: 0.1651 - val_acc: 0.9196\n",
            "Epoch 139/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1281 - acc: 0.9621 - val_loss: 0.1620 - val_acc: 0.9286\n",
            "Epoch 140/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1361 - acc: 0.9710 - val_loss: 0.1583 - val_acc: 0.9286\n",
            "Epoch 141/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1473 - acc: 0.9555 - val_loss: 0.1571 - val_acc: 0.9196\n",
            "Epoch 142/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1350 - acc: 0.9510 - val_loss: 0.1545 - val_acc: 0.9196\n",
            "Epoch 143/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1356 - acc: 0.9599 - val_loss: 0.1553 - val_acc: 0.9286\n",
            "Epoch 144/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1370 - acc: 0.9666 - val_loss: 0.1514 - val_acc: 0.9375\n",
            "Epoch 145/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1597 - acc: 0.9621 - val_loss: 0.1494 - val_acc: 0.9196\n",
            "Epoch 146/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1336 - acc: 0.9599 - val_loss: 0.1552 - val_acc: 0.9286\n",
            "Epoch 147/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1677 - acc: 0.9399 - val_loss: 0.1458 - val_acc: 0.9375\n",
            "Epoch 148/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1490 - acc: 0.9621 - val_loss: 0.1468 - val_acc: 0.9196\n",
            "Epoch 149/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1222 - acc: 0.9644 - val_loss: 0.1471 - val_acc: 0.9375\n",
            "Epoch 150/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1318 - acc: 0.9599 - val_loss: 0.1381 - val_acc: 0.9196\n",
            "Epoch 151/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1360 - acc: 0.9666 - val_loss: 0.1453 - val_acc: 0.9375\n",
            "Epoch 152/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1145 - acc: 0.9755 - val_loss: 0.1433 - val_acc: 0.9286\n",
            "Epoch 153/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1273 - acc: 0.9688 - val_loss: 0.1504 - val_acc: 0.9286\n",
            "Epoch 154/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1390 - acc: 0.9599 - val_loss: 0.1408 - val_acc: 0.9375\n",
            "Epoch 155/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1325 - acc: 0.9666 - val_loss: 0.1449 - val_acc: 0.9375\n",
            "Epoch 156/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1399 - acc: 0.9577 - val_loss: 0.1391 - val_acc: 0.9286\n",
            "Epoch 157/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1137 - acc: 0.9733 - val_loss: 0.1445 - val_acc: 0.9375\n",
            "Epoch 158/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1086 - acc: 0.9688 - val_loss: 0.1374 - val_acc: 0.9375\n",
            "Epoch 159/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1124 - acc: 0.9710 - val_loss: 0.1361 - val_acc: 0.9375\n",
            "Epoch 160/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1379 - acc: 0.9666 - val_loss: 0.1348 - val_acc: 0.9375\n",
            "Epoch 161/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1258 - acc: 0.9688 - val_loss: 0.1311 - val_acc: 0.9286\n",
            "Epoch 162/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1062 - acc: 0.9733 - val_loss: 0.1325 - val_acc: 0.9375\n",
            "Epoch 163/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1126 - acc: 0.9710 - val_loss: 0.1291 - val_acc: 0.9375\n",
            "Epoch 164/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1351 - acc: 0.9644 - val_loss: 0.1289 - val_acc: 0.9375\n",
            "Epoch 165/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1283 - acc: 0.9710 - val_loss: 0.1263 - val_acc: 0.9375\n",
            "Epoch 166/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1079 - acc: 0.9733 - val_loss: 0.1231 - val_acc: 0.9375\n",
            "Epoch 167/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1109 - acc: 0.9710 - val_loss: 0.1283 - val_acc: 0.9375\n",
            "Epoch 168/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1122 - acc: 0.9733 - val_loss: 0.1271 - val_acc: 0.9375\n",
            "Epoch 169/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1039 - acc: 0.9822 - val_loss: 0.1323 - val_acc: 0.9375\n",
            "Epoch 170/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1144 - acc: 0.9666 - val_loss: 0.1204 - val_acc: 0.9375\n",
            "Epoch 171/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1163 - acc: 0.9710 - val_loss: 0.1198 - val_acc: 0.9375\n",
            "Epoch 172/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0955 - acc: 0.9755 - val_loss: 0.1225 - val_acc: 0.9375\n",
            "Epoch 173/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0999 - acc: 0.9710 - val_loss: 0.1188 - val_acc: 0.9375\n",
            "Epoch 174/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1021 - acc: 0.9755 - val_loss: 0.1173 - val_acc: 0.9375\n",
            "Epoch 175/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1178 - acc: 0.9666 - val_loss: 0.1221 - val_acc: 0.9286\n",
            "Epoch 176/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1286 - acc: 0.9666 - val_loss: 0.1289 - val_acc: 0.9375\n",
            "Epoch 177/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1433 - acc: 0.9577 - val_loss: 0.1192 - val_acc: 0.9286\n",
            "Epoch 178/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1098 - acc: 0.9777 - val_loss: 0.1289 - val_acc: 0.9375\n",
            "Epoch 179/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1098 - acc: 0.9733 - val_loss: 0.1196 - val_acc: 0.9286\n",
            "Epoch 180/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0944 - acc: 0.9733 - val_loss: 0.1173 - val_acc: 0.9286\n",
            "Epoch 181/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1194 - acc: 0.9777 - val_loss: 0.1202 - val_acc: 0.9375\n",
            "Epoch 182/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1055 - acc: 0.9755 - val_loss: 0.1118 - val_acc: 0.9375\n",
            "Epoch 183/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1287 - acc: 0.9666 - val_loss: 0.1136 - val_acc: 0.9375\n",
            "Epoch 184/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0903 - acc: 0.9844 - val_loss: 0.1127 - val_acc: 0.9375\n",
            "Epoch 185/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0895 - acc: 0.9688 - val_loss: 0.1070 - val_acc: 0.9554\n",
            "Epoch 186/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0984 - acc: 0.9755 - val_loss: 0.1210 - val_acc: 0.9375\n",
            "Epoch 187/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0930 - acc: 0.9755 - val_loss: 0.1116 - val_acc: 0.9464\n",
            "Epoch 188/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1048 - acc: 0.9755 - val_loss: 0.1131 - val_acc: 0.9375\n",
            "Epoch 189/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0912 - acc: 0.9755 - val_loss: 0.1059 - val_acc: 0.9554\n",
            "Epoch 190/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0953 - acc: 0.9844 - val_loss: 0.1119 - val_acc: 0.9375\n",
            "Epoch 191/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1007 - val_acc: 0.9554\n",
            "Epoch 192/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0879 - acc: 0.9844 - val_loss: 0.1030 - val_acc: 0.9554\n",
            "Epoch 193/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1167 - acc: 0.9777 - val_loss: 0.1146 - val_acc: 0.9554\n",
            "Epoch 194/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1342 - acc: 0.9621 - val_loss: 0.1321 - val_acc: 0.9286\n",
            "Epoch 195/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1223 - acc: 0.9844 - val_loss: 0.1145 - val_acc: 0.9554\n",
            "Epoch 196/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1173 - acc: 0.9666 - val_loss: 0.1135 - val_acc: 0.9554\n",
            "Epoch 197/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1376 - acc: 0.9777 - val_loss: 0.1207 - val_acc: 0.9464\n",
            "Epoch 198/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1270 - acc: 0.9822 - val_loss: 0.1147 - val_acc: 0.9464\n",
            "Epoch 199/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1038 - acc: 0.9755 - val_loss: 0.1208 - val_acc: 0.9464\n",
            "Epoch 200/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1061 - acc: 0.9733 - val_loss: 0.1137 - val_acc: 0.9464\n",
            "Epoch 201/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1206 - acc: 0.9666 - val_loss: 0.1148 - val_acc: 0.9464\n",
            "Epoch 202/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0883 - acc: 0.9844 - val_loss: 0.1127 - val_acc: 0.9464\n",
            "Epoch 203/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1039 - acc: 0.9755 - val_loss: 0.1124 - val_acc: 0.9554\n",
            "Epoch 204/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1032 - acc: 0.9733 - val_loss: 0.1231 - val_acc: 0.9286\n",
            "Epoch 205/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1110 - acc: 0.9710 - val_loss: 0.1141 - val_acc: 0.9554\n",
            "Epoch 206/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0917 - acc: 0.9889 - val_loss: 0.1116 - val_acc: 0.9554\n",
            "Epoch 207/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1031 - acc: 0.9777 - val_loss: 0.1149 - val_acc: 0.9464\n",
            "Epoch 208/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0998 - acc: 0.9755 - val_loss: 0.1159 - val_acc: 0.9464\n",
            "Epoch 209/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1043 - acc: 0.9710 - val_loss: 0.1160 - val_acc: 0.9464\n",
            "Epoch 210/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1005 - acc: 0.9688 - val_loss: 0.1091 - val_acc: 0.9464\n",
            "Epoch 211/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1330 - acc: 0.9443 - val_loss: 0.1058 - val_acc: 0.9464\n",
            "Epoch 212/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1165 - acc: 0.9666 - val_loss: 0.1099 - val_acc: 0.9464\n",
            "Epoch 213/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0992 - acc: 0.9733 - val_loss: 0.1097 - val_acc: 0.9554\n",
            "Epoch 214/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0987 - acc: 0.9755 - val_loss: 0.1166 - val_acc: 0.9464\n",
            "Epoch 215/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1052 - acc: 0.9644 - val_loss: 0.1056 - val_acc: 0.9554\n",
            "Epoch 216/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1070 - acc: 0.9710 - val_loss: 0.1062 - val_acc: 0.9464\n",
            "Epoch 217/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1188 - acc: 0.9666 - val_loss: 0.1049 - val_acc: 0.9464\n",
            "Epoch 218/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0792 - acc: 0.9866 - val_loss: 0.1026 - val_acc: 0.9464\n",
            "Epoch 219/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0768 - acc: 0.9866 - val_loss: 0.0991 - val_acc: 0.9554\n",
            "Epoch 220/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1008 - acc: 0.9755 - val_loss: 0.0987 - val_acc: 0.9554\n",
            "Epoch 221/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1427 - acc: 0.9532 - val_loss: 0.1074 - val_acc: 0.9554\n",
            "Epoch 222/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1404 - acc: 0.9555 - val_loss: 0.1127 - val_acc: 0.9464\n",
            "Epoch 223/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1252 - acc: 0.9599 - val_loss: 0.1506 - val_acc: 0.9286\n",
            "Epoch 224/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1126 - acc: 0.9688 - val_loss: 0.1240 - val_acc: 0.9464\n",
            "Epoch 225/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0943 - acc: 0.9688 - val_loss: 0.1429 - val_acc: 0.9286\n",
            "Epoch 226/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0997 - acc: 0.9688 - val_loss: 0.1104 - val_acc: 0.9464\n",
            "Epoch 227/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0849 - acc: 0.9800 - val_loss: 0.1133 - val_acc: 0.9464\n",
            "Epoch 228/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0716 - acc: 0.9822 - val_loss: 0.1044 - val_acc: 0.9464\n",
            "Epoch 229/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0900 - acc: 0.9733 - val_loss: 0.1088 - val_acc: 0.9464\n",
            "Epoch 230/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0974 - acc: 0.9844 - val_loss: 0.1059 - val_acc: 0.9554\n",
            "Epoch 231/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0724 - acc: 0.9777 - val_loss: 0.1113 - val_acc: 0.9464\n",
            "Epoch 232/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0663 - acc: 0.9844 - val_loss: 0.1038 - val_acc: 0.9464\n",
            "Epoch 233/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0747 - acc: 0.9755 - val_loss: 0.1293 - val_acc: 0.9464\n",
            "Epoch 234/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0871 - acc: 0.9800 - val_loss: 0.1050 - val_acc: 0.9554\n",
            "Epoch 235/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0910 - acc: 0.9800 - val_loss: 0.1087 - val_acc: 0.9464\n",
            "Epoch 236/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0655 - acc: 0.9844 - val_loss: 0.0998 - val_acc: 0.9554\n",
            "Epoch 237/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0715 - acc: 0.9844 - val_loss: 0.1255 - val_acc: 0.9464\n",
            "Epoch 238/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0855 - acc: 0.9800 - val_loss: 0.1002 - val_acc: 0.9554\n",
            "Epoch 239/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0643 - acc: 0.9822 - val_loss: 0.1033 - val_acc: 0.9464\n",
            "Epoch 240/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0755 - acc: 0.9800 - val_loss: 0.0991 - val_acc: 0.9554\n",
            "Epoch 241/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0636 - acc: 0.9866 - val_loss: 0.1078 - val_acc: 0.9464\n",
            "Epoch 242/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0732 - acc: 0.9889 - val_loss: 0.1009 - val_acc: 0.9464\n",
            "Epoch 243/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0718 - acc: 0.9844 - val_loss: 0.0991 - val_acc: 0.9464\n",
            "Epoch 244/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0790 - acc: 0.9822 - val_loss: 0.1005 - val_acc: 0.9464\n",
            "Epoch 245/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0825 - acc: 0.9777 - val_loss: 0.1018 - val_acc: 0.9554\n",
            "Epoch 246/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0653 - acc: 0.9844 - val_loss: 0.1021 - val_acc: 0.9464\n",
            "Epoch 247/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0678 - acc: 0.9889 - val_loss: 0.0987 - val_acc: 0.9554\n",
            "Epoch 248/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0711 - acc: 0.9777 - val_loss: 0.0997 - val_acc: 0.9554\n",
            "Epoch 249/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0687 - acc: 0.9844 - val_loss: 0.1016 - val_acc: 0.9554\n",
            "Epoch 250/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0631 - acc: 0.9866 - val_loss: 0.1002 - val_acc: 0.9554\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1002 - acc: 0.9554\n",
            "Accuracy: : 95.54%\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 64)                63424     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " re_lu_12 (ReLU)             (None, 64)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " re_lu_13 (ReLU)             (None, 32)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,537\n",
            "Trainable params: 65,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/400\n",
            "15/15 [==============================] - 1s 21ms/step - loss: 0.6813 - acc: 0.5902 - val_loss: 0.6764 - val_acc: 0.5982\n",
            "Epoch 2/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6741 - acc: 0.5969 - val_loss: 0.6702 - val_acc: 0.5982\n",
            "Epoch 3/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6775 - acc: 0.5924 - val_loss: 0.6702 - val_acc: 0.5982\n",
            "Epoch 4/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6814 - acc: 0.5969 - val_loss: 0.6696 - val_acc: 0.5982\n",
            "Epoch 5/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.5991 - val_loss: 0.6664 - val_acc: 0.5982\n",
            "Epoch 6/400\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.6687 - acc: 0.5969 - val_loss: 0.6637 - val_acc: 0.5982\n",
            "Epoch 7/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6653 - acc: 0.5969 - val_loss: 0.6610 - val_acc: 0.5982\n",
            "Epoch 8/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6629 - acc: 0.5969 - val_loss: 0.6594 - val_acc: 0.5982\n",
            "Epoch 9/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6648 - acc: 0.5969 - val_loss: 0.6574 - val_acc: 0.5982\n",
            "Epoch 10/400\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.6595 - acc: 0.5991 - val_loss: 0.6558 - val_acc: 0.5982\n",
            "Epoch 11/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6582 - acc: 0.5969 - val_loss: 0.6518 - val_acc: 0.5982\n",
            "Epoch 12/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6558 - acc: 0.5969 - val_loss: 0.6486 - val_acc: 0.5982\n",
            "Epoch 13/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6463 - acc: 0.6013 - val_loss: 0.6439 - val_acc: 0.5982\n",
            "Epoch 14/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6488 - acc: 0.6125 - val_loss: 0.6395 - val_acc: 0.5982\n",
            "Epoch 15/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6449 - acc: 0.6058 - val_loss: 0.6318 - val_acc: 0.6071\n",
            "Epoch 16/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6358 - acc: 0.6548 - val_loss: 0.6280 - val_acc: 0.6071\n",
            "Epoch 17/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6230 - acc: 0.6258 - val_loss: 0.6204 - val_acc: 0.6071\n",
            "Epoch 18/400\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.6219 - acc: 0.6192 - val_loss: 0.6098 - val_acc: 0.6071\n",
            "Epoch 19/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6146 - acc: 0.6592 - val_loss: 0.6029 - val_acc: 0.6429\n",
            "Epoch 20/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6181 - acc: 0.6147 - val_loss: 0.6048 - val_acc: 0.6071\n",
            "Epoch 21/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5927 - acc: 0.6882 - val_loss: 0.5872 - val_acc: 0.6786\n",
            "Epoch 22/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5914 - acc: 0.6971 - val_loss: 0.5799 - val_acc: 0.6429\n",
            "Epoch 23/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5830 - acc: 0.7127 - val_loss: 0.5653 - val_acc: 0.7411\n",
            "Epoch 24/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5859 - acc: 0.7372 - val_loss: 0.5548 - val_acc: 0.7321\n",
            "Epoch 25/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5703 - acc: 0.7572 - val_loss: 0.5453 - val_acc: 0.7232\n",
            "Epoch 26/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.5534 - acc: 0.7528 - val_loss: 0.5298 - val_acc: 0.7411\n",
            "Epoch 27/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5484 - acc: 0.7416 - val_loss: 0.5203 - val_acc: 0.7411\n",
            "Epoch 28/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5355 - acc: 0.7639 - val_loss: 0.5108 - val_acc: 0.7500\n",
            "Epoch 29/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5267 - acc: 0.7661 - val_loss: 0.4984 - val_acc: 0.7500\n",
            "Epoch 30/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5224 - acc: 0.7595 - val_loss: 0.4806 - val_acc: 0.8214\n",
            "Epoch 31/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5064 - acc: 0.7751 - val_loss: 0.4730 - val_acc: 0.7857\n",
            "Epoch 32/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4966 - acc: 0.7773 - val_loss: 0.4572 - val_acc: 0.8036\n",
            "Epoch 33/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4936 - acc: 0.7728 - val_loss: 0.4480 - val_acc: 0.8036\n",
            "Epoch 34/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4898 - acc: 0.7684 - val_loss: 0.4369 - val_acc: 0.8393\n",
            "Epoch 35/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4613 - acc: 0.8151 - val_loss: 0.4231 - val_acc: 0.8393\n",
            "Epoch 36/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4513 - acc: 0.8285 - val_loss: 0.4168 - val_acc: 0.8304\n",
            "Epoch 37/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4449 - acc: 0.7906 - val_loss: 0.3967 - val_acc: 0.8571\n",
            "Epoch 38/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4223 - acc: 0.8486 - val_loss: 0.3840 - val_acc: 0.8571\n",
            "Epoch 39/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4164 - acc: 0.8396 - val_loss: 0.3744 - val_acc: 0.8571\n",
            "Epoch 40/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4012 - acc: 0.8486 - val_loss: 0.3604 - val_acc: 0.8839\n",
            "Epoch 41/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4010 - acc: 0.8575 - val_loss: 0.3594 - val_acc: 0.8571\n",
            "Epoch 42/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3931 - acc: 0.8552 - val_loss: 0.3479 - val_acc: 0.8750\n",
            "Epoch 43/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3829 - acc: 0.8619 - val_loss: 0.3319 - val_acc: 0.8929\n",
            "Epoch 44/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3805 - acc: 0.8708 - val_loss: 0.3290 - val_acc: 0.8929\n",
            "Epoch 45/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3739 - acc: 0.8619 - val_loss: 0.3115 - val_acc: 0.8929\n",
            "Epoch 46/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3658 - acc: 0.8842 - val_loss: 0.3017 - val_acc: 0.9107\n",
            "Epoch 47/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3490 - acc: 0.9020 - val_loss: 0.2997 - val_acc: 0.8929\n",
            "Epoch 48/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3461 - acc: 0.8864 - val_loss: 0.2878 - val_acc: 0.9018\n",
            "Epoch 49/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3321 - acc: 0.8797 - val_loss: 0.2895 - val_acc: 0.8929\n",
            "Epoch 50/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3438 - acc: 0.8931 - val_loss: 0.2851 - val_acc: 0.9196\n",
            "Epoch 51/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3105 - acc: 0.8998 - val_loss: 0.2890 - val_acc: 0.8929\n",
            "Epoch 52/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3200 - acc: 0.8953 - val_loss: 0.2679 - val_acc: 0.9018\n",
            "Epoch 53/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3141 - acc: 0.8953 - val_loss: 0.2733 - val_acc: 0.9464\n",
            "Epoch 54/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3670 - acc: 0.8708 - val_loss: 0.3271 - val_acc: 0.8929\n",
            "Epoch 55/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3781 - acc: 0.8775 - val_loss: 0.2903 - val_acc: 0.9286\n",
            "Epoch 56/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3609 - acc: 0.8686 - val_loss: 0.2836 - val_acc: 0.9464\n",
            "Epoch 57/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3642 - acc: 0.8864 - val_loss: 0.2847 - val_acc: 0.9018\n",
            "Epoch 58/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3713 - acc: 0.8731 - val_loss: 0.3109 - val_acc: 0.9464\n",
            "Epoch 59/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3437 - acc: 0.8909 - val_loss: 0.2679 - val_acc: 0.9107\n",
            "Epoch 60/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3224 - acc: 0.8753 - val_loss: 0.2602 - val_acc: 0.9196\n",
            "Epoch 61/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3104 - acc: 0.9220 - val_loss: 0.2535 - val_acc: 0.9196\n",
            "Epoch 62/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3091 - acc: 0.8998 - val_loss: 0.2491 - val_acc: 0.9196\n",
            "Epoch 63/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3020 - acc: 0.9042 - val_loss: 0.2536 - val_acc: 0.9018\n",
            "Epoch 64/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3192 - acc: 0.8686 - val_loss: 0.2481 - val_acc: 0.9286\n",
            "Epoch 65/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2981 - acc: 0.8842 - val_loss: 0.2358 - val_acc: 0.9196\n",
            "Epoch 66/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2863 - acc: 0.9020 - val_loss: 0.2352 - val_acc: 0.9196\n",
            "Epoch 67/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2726 - acc: 0.9087 - val_loss: 0.2335 - val_acc: 0.9196\n",
            "Epoch 68/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2812 - acc: 0.9109 - val_loss: 0.2363 - val_acc: 0.9196\n",
            "Epoch 69/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2717 - acc: 0.9154 - val_loss: 0.2222 - val_acc: 0.9196\n",
            "Epoch 70/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2813 - acc: 0.9131 - val_loss: 0.2217 - val_acc: 0.9196\n",
            "Epoch 71/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2749 - acc: 0.9109 - val_loss: 0.2158 - val_acc: 0.9286\n",
            "Epoch 72/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2459 - acc: 0.9220 - val_loss: 0.2107 - val_acc: 0.9286\n",
            "Epoch 73/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2558 - acc: 0.9176 - val_loss: 0.2197 - val_acc: 0.9196\n",
            "Epoch 74/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2702 - acc: 0.9087 - val_loss: 0.2164 - val_acc: 0.9196\n",
            "Epoch 75/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2619 - acc: 0.9243 - val_loss: 0.2077 - val_acc: 0.9286\n",
            "Epoch 76/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2471 - acc: 0.9421 - val_loss: 0.2054 - val_acc: 0.9286\n",
            "Epoch 77/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2171 - acc: 0.9310 - val_loss: 0.2208 - val_acc: 0.9196\n",
            "Epoch 78/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2509 - acc: 0.9220 - val_loss: 0.2046 - val_acc: 0.9286\n",
            "Epoch 79/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2306 - acc: 0.9443 - val_loss: 0.2015 - val_acc: 0.9286\n",
            "Epoch 80/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2317 - acc: 0.9310 - val_loss: 0.1975 - val_acc: 0.9286\n",
            "Epoch 81/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2196 - acc: 0.9310 - val_loss: 0.2051 - val_acc: 0.9196\n",
            "Epoch 82/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2149 - acc: 0.9310 - val_loss: 0.1965 - val_acc: 0.9286\n",
            "Epoch 83/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2358 - acc: 0.9287 - val_loss: 0.1864 - val_acc: 0.9643\n",
            "Epoch 84/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2399 - acc: 0.9310 - val_loss: 0.1869 - val_acc: 0.9464\n",
            "Epoch 85/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2176 - acc: 0.9354 - val_loss: 0.1922 - val_acc: 0.9286\n",
            "Epoch 86/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2175 - acc: 0.9332 - val_loss: 0.1857 - val_acc: 0.9286\n",
            "Epoch 87/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2220 - acc: 0.9243 - val_loss: 0.1966 - val_acc: 0.9286\n",
            "Epoch 88/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2155 - acc: 0.9310 - val_loss: 0.1834 - val_acc: 0.9375\n",
            "Epoch 89/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2080 - acc: 0.9354 - val_loss: 0.2152 - val_acc: 0.9196\n",
            "Epoch 90/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2943 - acc: 0.8953 - val_loss: 0.2155 - val_acc: 0.9464\n",
            "Epoch 91/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2481 - acc: 0.9287 - val_loss: 0.2028 - val_acc: 0.9196\n",
            "Epoch 92/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1796 - acc: 0.9488 - val_loss: 0.1751 - val_acc: 0.9643\n",
            "Epoch 93/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2177 - acc: 0.9310 - val_loss: 0.1823 - val_acc: 0.9286\n",
            "Epoch 94/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1953 - acc: 0.9465 - val_loss: 0.1714 - val_acc: 0.9643\n",
            "Epoch 95/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1936 - acc: 0.9599 - val_loss: 0.1768 - val_acc: 0.9286\n",
            "Epoch 96/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1912 - acc: 0.9465 - val_loss: 0.1853 - val_acc: 0.9286\n",
            "Epoch 97/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2057 - acc: 0.9332 - val_loss: 0.1751 - val_acc: 0.9286\n",
            "Epoch 98/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1794 - acc: 0.9443 - val_loss: 0.1675 - val_acc: 0.9643\n",
            "Epoch 99/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1728 - acc: 0.9443 - val_loss: 0.1755 - val_acc: 0.9286\n",
            "Epoch 100/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1879 - acc: 0.9399 - val_loss: 0.1670 - val_acc: 0.9643\n",
            "Epoch 101/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1784 - acc: 0.9510 - val_loss: 0.1803 - val_acc: 0.9286\n",
            "Epoch 102/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1953 - acc: 0.9332 - val_loss: 0.1645 - val_acc: 0.9643\n",
            "Epoch 103/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1721 - acc: 0.9532 - val_loss: 0.1786 - val_acc: 0.9286\n",
            "Epoch 104/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1567 - acc: 0.9577 - val_loss: 0.1633 - val_acc: 0.9554\n",
            "Epoch 105/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1519 - acc: 0.9755 - val_loss: 0.1780 - val_acc: 0.9286\n",
            "Epoch 106/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1763 - acc: 0.9532 - val_loss: 0.1607 - val_acc: 0.9554\n",
            "Epoch 107/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1542 - acc: 0.9465 - val_loss: 0.1742 - val_acc: 0.9286\n",
            "Epoch 108/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1537 - acc: 0.9465 - val_loss: 0.1676 - val_acc: 0.9375\n",
            "Epoch 109/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1689 - acc: 0.9488 - val_loss: 0.1692 - val_acc: 0.9375\n",
            "Epoch 110/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1668 - acc: 0.9644 - val_loss: 0.1580 - val_acc: 0.9643\n",
            "Epoch 111/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1480 - acc: 0.9555 - val_loss: 0.1640 - val_acc: 0.9375\n",
            "Epoch 112/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1672 - acc: 0.9421 - val_loss: 0.1700 - val_acc: 0.9464\n",
            "Epoch 113/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1606 - acc: 0.9599 - val_loss: 0.1729 - val_acc: 0.9375\n",
            "Epoch 114/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1422 - acc: 0.9555 - val_loss: 0.1644 - val_acc: 0.9375\n",
            "Epoch 115/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1825 - acc: 0.9465 - val_loss: 0.1594 - val_acc: 0.9464\n",
            "Epoch 116/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1571 - acc: 0.9577 - val_loss: 0.1545 - val_acc: 0.9643\n",
            "Epoch 117/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1808 - acc: 0.9198 - val_loss: 0.1742 - val_acc: 0.9375\n",
            "Epoch 118/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1728 - acc: 0.9465 - val_loss: 0.1570 - val_acc: 0.9554\n",
            "Epoch 119/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1759 - acc: 0.9443 - val_loss: 0.1543 - val_acc: 0.9643\n",
            "Epoch 120/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1306 - acc: 0.9599 - val_loss: 0.1622 - val_acc: 0.9464\n",
            "Epoch 121/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1452 - acc: 0.9532 - val_loss: 0.1654 - val_acc: 0.9464\n",
            "Epoch 122/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1569 - acc: 0.9532 - val_loss: 0.1667 - val_acc: 0.9464\n",
            "Epoch 123/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1681 - acc: 0.9510 - val_loss: 0.1526 - val_acc: 0.9643\n",
            "Epoch 124/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1433 - acc: 0.9621 - val_loss: 0.1638 - val_acc: 0.9464\n",
            "Epoch 125/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1369 - acc: 0.9666 - val_loss: 0.1663 - val_acc: 0.9464\n",
            "Epoch 126/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1310 - acc: 0.9532 - val_loss: 0.1689 - val_acc: 0.9464\n",
            "Epoch 127/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1343 - acc: 0.9644 - val_loss: 0.1591 - val_acc: 0.9464\n",
            "Epoch 128/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1750 - acc: 0.9220 - val_loss: 0.1582 - val_acc: 0.9464\n",
            "Epoch 129/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1558 - acc: 0.9488 - val_loss: 0.1407 - val_acc: 0.9643\n",
            "Epoch 130/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1356 - acc: 0.9733 - val_loss: 0.1618 - val_acc: 0.9464\n",
            "Epoch 131/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1263 - acc: 0.9666 - val_loss: 0.1446 - val_acc: 0.9732\n",
            "Epoch 132/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1318 - acc: 0.9644 - val_loss: 0.1616 - val_acc: 0.9464\n",
            "Epoch 133/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1187 - acc: 0.9800 - val_loss: 0.1562 - val_acc: 0.9464\n",
            "Epoch 134/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1179 - acc: 0.9733 - val_loss: 0.1520 - val_acc: 0.9643\n",
            "Epoch 135/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1165 - acc: 0.9688 - val_loss: 0.1608 - val_acc: 0.9464\n",
            "Epoch 136/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1092 - acc: 0.9621 - val_loss: 0.1422 - val_acc: 0.9732\n",
            "Epoch 137/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1154 - acc: 0.9755 - val_loss: 0.1632 - val_acc: 0.9464\n",
            "Epoch 138/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1183 - acc: 0.9666 - val_loss: 0.1405 - val_acc: 0.9732\n",
            "Epoch 139/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1291 - acc: 0.9644 - val_loss: 0.1646 - val_acc: 0.9464\n",
            "Epoch 140/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1017 - acc: 0.9710 - val_loss: 0.1374 - val_acc: 0.9732\n",
            "Epoch 141/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1580 - acc: 0.9510 - val_loss: 0.1849 - val_acc: 0.9375\n",
            "Epoch 142/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1112 - acc: 0.9755 - val_loss: 0.1413 - val_acc: 0.9732\n",
            "Epoch 143/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1142 - acc: 0.9688 - val_loss: 0.1734 - val_acc: 0.9464\n",
            "Epoch 144/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1145 - acc: 0.9666 - val_loss: 0.1493 - val_acc: 0.9643\n",
            "Epoch 145/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1057 - acc: 0.9844 - val_loss: 0.1807 - val_acc: 0.9464\n",
            "Epoch 146/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1257 - acc: 0.9621 - val_loss: 0.1372 - val_acc: 0.9732\n",
            "Epoch 147/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1114 - acc: 0.9621 - val_loss: 0.1559 - val_acc: 0.9554\n",
            "Epoch 148/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1377 - acc: 0.9621 - val_loss: 0.1493 - val_acc: 0.9643\n",
            "Epoch 149/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1114 - acc: 0.9733 - val_loss: 0.1434 - val_acc: 0.9732\n",
            "Epoch 150/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1165 - acc: 0.9755 - val_loss: 0.1593 - val_acc: 0.9464\n",
            "Epoch 151/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0996 - acc: 0.9800 - val_loss: 0.1541 - val_acc: 0.9554\n",
            "Epoch 152/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1073 - acc: 0.9710 - val_loss: 0.1489 - val_acc: 0.9643\n",
            "Epoch 153/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0995 - acc: 0.9733 - val_loss: 0.1514 - val_acc: 0.9643\n",
            "Epoch 154/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1109 - acc: 0.9755 - val_loss: 0.1371 - val_acc: 0.9732\n",
            "Epoch 155/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0896 - acc: 0.9866 - val_loss: 0.1481 - val_acc: 0.9643\n",
            "Epoch 156/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1147 - acc: 0.9688 - val_loss: 0.1597 - val_acc: 0.9554\n",
            "Epoch 157/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0865 - acc: 0.9866 - val_loss: 0.1386 - val_acc: 0.9732\n",
            "Epoch 158/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1128 - acc: 0.9688 - val_loss: 0.1476 - val_acc: 0.9643\n",
            "Epoch 159/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0860 - acc: 0.9822 - val_loss: 0.1476 - val_acc: 0.9643\n",
            "Epoch 160/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1143 - acc: 0.9710 - val_loss: 0.1505 - val_acc: 0.9643\n",
            "Epoch 161/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1634 - val_acc: 0.9464\n",
            "Epoch 162/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1253 - acc: 0.9577 - val_loss: 0.1472 - val_acc: 0.9643\n",
            "Epoch 163/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1014 - acc: 0.9733 - val_loss: 0.1626 - val_acc: 0.9554\n",
            "Epoch 164/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0992 - acc: 0.9755 - val_loss: 0.1498 - val_acc: 0.9643\n",
            "Epoch 165/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0953 - acc: 0.9844 - val_loss: 0.1447 - val_acc: 0.9643\n",
            "Epoch 166/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1260 - acc: 0.9688 - val_loss: 0.1747 - val_acc: 0.9464\n",
            "Epoch 167/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1041 - acc: 0.9688 - val_loss: 0.1442 - val_acc: 0.9643\n",
            "Epoch 168/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0850 - acc: 0.9777 - val_loss: 0.1825 - val_acc: 0.9464\n",
            "Epoch 169/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0882 - acc: 0.9755 - val_loss: 0.1662 - val_acc: 0.9554\n",
            "Epoch 170/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1452 - acc: 0.9443 - val_loss: 0.1381 - val_acc: 0.9821\n",
            "Epoch 171/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0850 - acc: 0.9822 - val_loss: 0.1799 - val_acc: 0.9464\n",
            "Epoch 172/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1220 - acc: 0.9644 - val_loss: 0.1457 - val_acc: 0.9643\n",
            "Epoch 173/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1194 - acc: 0.9688 - val_loss: 0.1624 - val_acc: 0.9643\n",
            "Epoch 174/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0811 - acc: 0.9800 - val_loss: 0.1840 - val_acc: 0.9464\n",
            "Epoch 175/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0922 - acc: 0.9800 - val_loss: 0.1491 - val_acc: 0.9643\n",
            "Epoch 176/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0918 - acc: 0.9733 - val_loss: 0.1682 - val_acc: 0.9554\n",
            "Epoch 177/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0714 - acc: 0.9866 - val_loss: 0.1640 - val_acc: 0.9643\n",
            "Epoch 178/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0789 - acc: 0.9800 - val_loss: 0.1430 - val_acc: 0.9732\n",
            "Epoch 179/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0787 - acc: 0.9822 - val_loss: 0.1472 - val_acc: 0.9643\n",
            "Epoch 180/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0933 - acc: 0.9777 - val_loss: 0.1748 - val_acc: 0.9464\n",
            "Epoch 181/400\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0830 - acc: 0.9800 - val_loss: 0.1330 - val_acc: 0.9821\n",
            "Epoch 182/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2009 - acc: 0.9176 - val_loss: 0.2401 - val_acc: 0.9196\n",
            "Epoch 183/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1194 - acc: 0.9555 - val_loss: 0.1398 - val_acc: 0.9732\n",
            "Epoch 184/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1024 - acc: 0.9755 - val_loss: 0.1846 - val_acc: 0.9464\n",
            "Epoch 185/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1170 - acc: 0.9777 - val_loss: 0.1483 - val_acc: 0.9643\n",
            "Epoch 186/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0947 - acc: 0.9710 - val_loss: 0.1608 - val_acc: 0.9554\n",
            "Epoch 187/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0900 - acc: 0.9800 - val_loss: 0.1652 - val_acc: 0.9554\n",
            "Epoch 188/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0800 - acc: 0.9800 - val_loss: 0.1554 - val_acc: 0.9643\n",
            "Epoch 189/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0886 - acc: 0.9733 - val_loss: 0.1789 - val_acc: 0.9554\n",
            "Epoch 190/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0789 - acc: 0.9844 - val_loss: 0.1695 - val_acc: 0.9554\n",
            "Epoch 191/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0630 - acc: 0.9866 - val_loss: 0.1575 - val_acc: 0.9643\n",
            "Epoch 192/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0821 - acc: 0.9800 - val_loss: 0.1715 - val_acc: 0.9554\n",
            "Epoch 193/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0673 - acc: 0.9911 - val_loss: 0.1547 - val_acc: 0.9643\n",
            "Epoch 194/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0615 - acc: 0.9933 - val_loss: 0.1422 - val_acc: 0.9732\n",
            "Epoch 195/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1526 - acc: 0.9421 - val_loss: 0.1680 - val_acc: 0.9464\n",
            "Epoch 196/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1351 - acc: 0.9465 - val_loss: 0.1567 - val_acc: 0.9554\n",
            "Epoch 197/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1070 - acc: 0.9666 - val_loss: 0.1341 - val_acc: 0.9732\n",
            "Epoch 198/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0907 - acc: 0.9733 - val_loss: 0.1660 - val_acc: 0.9464\n",
            "Epoch 199/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0932 - acc: 0.9777 - val_loss: 0.1544 - val_acc: 0.9643\n",
            "Epoch 200/400\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1056 - acc: 0.9688 - val_loss: 0.1745 - val_acc: 0.9464\n",
            "Epoch 201/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0821 - acc: 0.9777 - val_loss: 0.1373 - val_acc: 0.9821\n",
            "Epoch 202/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0643 - acc: 0.9889 - val_loss: 0.1806 - val_acc: 0.9464\n",
            "Epoch 203/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0875 - acc: 0.9822 - val_loss: 0.1705 - val_acc: 0.9643\n",
            "Epoch 204/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0774 - acc: 0.9822 - val_loss: 0.1678 - val_acc: 0.9643\n",
            "Epoch 205/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0838 - acc: 0.9844 - val_loss: 0.1601 - val_acc: 0.9643\n",
            "Epoch 206/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0815 - acc: 0.9777 - val_loss: 0.1696 - val_acc: 0.9643\n",
            "Epoch 207/400\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1200 - acc: 0.9555 - val_loss: 0.1638 - val_acc: 0.9643\n",
            "Epoch 208/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0890 - acc: 0.9755 - val_loss: 0.1698 - val_acc: 0.9643\n",
            "Epoch 209/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0705 - acc: 0.9889 - val_loss: 0.1754 - val_acc: 0.9643\n",
            "Epoch 210/400\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1132 - acc: 0.9577 - val_loss: 0.1420 - val_acc: 0.9821\n",
            "Epoch 211/400\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0932 - acc: 0.9755 - val_loss: 0.2048 - val_acc: 0.9464\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2048 - acc: 0.9464\n",
            "Accuracy: : 94.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the results after folds\n",
        "print()\n",
        "print(\"Total Cross Validation Acc: %.2f%% (+/- %.2f%%)\"\n",
        "                                % (np.mean(crs_val_fold), np.std(crs_val_fold)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcmOA4tPRMNN",
        "outputId": "846f9659-d9e8-4880-cfaa-83eee3b5fa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Cross Validation Acc: 94.54% (+/- 1.28%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix for all folds (total conf_mat is sum of each folds)\n",
        "print('Confusion matrix: ')\n",
        "total_conf = np.zeros((2,2))\n",
        "for mat in conf_arr:\n",
        "    total_conf += np.array(mat)\n",
        "print(total_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCJCBo0MSonP",
        "outputId": "547d9b56-6475-48a0-e71e-8ede24019d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix: \n",
            "[[324.  11.]\n",
            " [ 20. 206.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the each fold model results and plot the best one\n",
        "# Basic method of max extraction\n",
        "best_acc = history_rec[0]\n",
        "for elem in history_rec:\n",
        "    if np.mean(elem.history['acc']) > np.mean(best_acc.history['acc']):\n",
        "        best_acc = elem"
      ],
      "metadata": {
        "id": "OoY0TUCwSqsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train and test accuraccy score\n",
        "plt.plot(best_acc.history['acc'], label='train')\n",
        "plt.plot(best_acc.history['val_acc'], label='test')\n",
        "plt.plot(best_acc.history['loss'], label='train')\n",
        "plt.plot(best_acc.history['val_loss'], label='test')\n",
        "plt.title('Train/Test Accuracy Graph')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1-_QqtkaStEI",
        "outputId": "40022215-e2e3-4ef2-87aa-d70057d4aa07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d9jSweLISu6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}